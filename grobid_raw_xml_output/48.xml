<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Artificial Intelligence Methods for Diagnostic and Decision-Making Assistance in Chronic Wounds: A Systematic Review</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">David</forename><surname>Reifs Jiménez</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">C/ Sagrada Familia</orgName>
								<orgName type="laboratory">Digital Care Research Group</orgName>
								<orgName type="institution">University of Vic</orgName>
								<address>
									<postCode>08500</postCode>
									<settlement>Vic, Barcelona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Lorena</forename><surname>Casanova-Lozano</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">C/ Sagrada Familia</orgName>
								<orgName type="laboratory">Digital Care Research Group</orgName>
								<orgName type="institution">University of Vic</orgName>
								<address>
									<postCode>08500</postCode>
									<settlement>Vic, Barcelona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">C/ Sagrada Familia</orgName>
								<orgName type="laboratory">Digital Care Research Group</orgName>
								<orgName type="institution">University of Vic</orgName>
								<address>
									<postCode>08500</postCode>
									<settlement>Vic, Barcelona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Sergi</forename><surname>Grau-Carrión</surname></persName>
							<email>sergi.grau@uvic.cat</email>
							<affiliation key="aff0">
								<orgName type="department">C/ Sagrada Familia</orgName>
								<orgName type="laboratory">Digital Care Research Group</orgName>
								<orgName type="institution">University of Vic</orgName>
								<address>
									<postCode>08500</postCode>
									<settlement>Vic, Barcelona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">C/ Sagrada Familia</orgName>
								<orgName type="laboratory">Digital Care Research Group</orgName>
								<orgName type="institution">University of Vic</orgName>
								<address>
									<postCode>08500</postCode>
									<settlement>Vic, Barcelona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ramon</forename><surname>Reig-Bolaño</surname></persName>
							<email>ramon.reig@uvic.cat</email>
							<affiliation key="aff0">
								<orgName type="department">C/ Sagrada Familia</orgName>
								<orgName type="laboratory">Digital Care Research Group</orgName>
								<orgName type="institution">University of Vic</orgName>
								<address>
									<postCode>08500</postCode>
									<settlement>Vic, Barcelona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">C/ Sagrada Familia</orgName>
								<orgName type="laboratory">Digital Care Research Group</orgName>
								<orgName type="institution">University of Vic</orgName>
								<address>
									<postCode>08500</postCode>
									<settlement>Vic, Barcelona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Artificial Intelligence Methods for Diagnostic and Decision-Making Assistance in Chronic Wounds: A Systematic Review</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C37C6811D027B07F2640C5929FAD7A20</idno>
					<idno type="DOI">10.1007/s10916-025-02153-8</idno>
					<note type="submission">Received: 25 October 2024 / Accepted: 24 January 2025 Keywords Wounds and injuries • Algorithms • data mining • Deep learning • Computer assisted • Decision support systems B David Reifs Jiménez The inclusion criteria for this systematic review encompassed articles published between January 1, 2013, and May 1, 2023,</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2025-08-13T17:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Chronic wounds, which take over four weeks to heal, are a major global health issue linked to conditions such as diabetes, venous insufficiency, arterial diseases, and pressure ulcers. These wounds cause pain, reduce quality of life, and impose significant economic burdens. This systematic review explores the impact of technological advancements on the diagnosis of chronic wounds, focusing on how computational methods in wound image and data analysis improve diagnostic precision and patient outcomes. A literature search was conducted in databases including ACM, IEEE, PubMed, Scopus, and Web of Science, covering studies from 2013 to 2023. The focus was on articles applying complex computational techniques to analyze chronic wound images and clinical data. Exclusion criteria were non-image samples, review articles, and non-English or non-Spanish texts. From 2,791 articles identified, 93 full-text studies were selected for final analysis. The review identified significant advancements in tissue classification, wound measurement, segmentation, prediction of wound aetiology, risk indicators, and healing potential. The use of image-based and data-driven methods has proven to enhance diagnostic accuracy and treatment efficiency in chronic wound care. The integration of technology into chronic wound diagnosis has shown a transformative effect, improving diagnostic capabilities, patient care, and reducing healthcare costs. Continued research and innovation in computational techniques are essential to unlock their full potential in managing chronic wounds effectively.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="20" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="21" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="22" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="23" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="24" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="25" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="26" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="27" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="28" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="29" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="30" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="31" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="32" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="33" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="34" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="35" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="36" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="37" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="38" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
		<surface n="39" ulx="0.0" uly="0.0" lrx="595.276" lry="790.866"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>A chronic wound is a wound that fails to heal within the expected timeframe, typically beyond 4-6 weeks, and does not progress through the normal stages of healing (inflammatory, proliferative, and remodeling) <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. Chronic wounds remain in a stalled phase due to factors such as underlying medical conditions, poor blood supply, or inadequate treatment <ref type="bibr" target="#b2">[3]</ref>. In contrast, a hard-to-heal wound refers to a wound that initially begins healing but fails to show signifi-cant reduction in size (20%-40%) within the first 2-4 weeks of optimal treatment <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>. While hard-to-heal wounds may eventually become chronic if healing is not achieved over time, not all chronic wounds are initially hard-to-heal <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>.</p><p>The key difference lies in the time frame and stage of healing: chronic wounds are defined by prolonged healing beyond 6 weeks, while hard-to-heal wounds show resistance to healing early in the process. In either case, these wounds can result from various underlying factors, such as the age of the patient and the presence of underlying chronic comorbidities <ref type="bibr" target="#b8">[8]</ref>. The prevalence of chronic wounds is more significant than most people realize, making it a silent epidemic <ref type="bibr" target="#b9">[9]</ref>. According to the World Health Organization (WHO), an estimated 4.5 million people worldwide suffer from chronic wounds at any given time. This number is expected to rise due to the aging population, the increasing prevalence of conditions like diabetes and obesity, and a growing number of people with reduced mobility <ref type="bibr" target="#b10">[10]</ref>. Diabetes, in particular, is a leading cause of chronic wounds. Diabetic foot ulcers (DFU) alone affect approximately 15% of individuals with diabetes during their lifetime, and it's estimated that 1 in 4 diabetics will expe-rience a foot ulcer at some point <ref type="bibr" target="#b11">[11]</ref>. The impact of chronic wounds on patients' lives cannot be underrated. Besides the physical pain and discomfort, chronic wounds often lead to emotional distress and decreased mental well-being. Patients may experience anxiety, depression, social isolation, and a loss of independence due to restricted mobility <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b12">12]</ref>. The risk of infection is another significant concern with chronic wounds, as they create an entry point for bacteria and can lead to amputations, further exacerbating the physical and psychological burden on affected individuals <ref type="bibr" target="#b13">[13]</ref>.</p><p>Chronic wounds place a substantial financial burden on healthcare systems and society. Treatment costs for managing chronic wounds are high, often requiring specialized wound care products, prolonged hospital stays, and frequent follow-up visits <ref type="bibr" target="#b14">[14]</ref>. It is often believed that the use of wound dressings per se is the major cost driver in wound management, whereas, in fact, nursing time and hospital costs are together responsible for around 80-85% of the total cost <ref type="bibr" target="#b8">[8]</ref>. For a diabetic foot wound alone, the estimated cost of treatment is approximately 10,000 euros <ref type="bibr" target="#b15">[15]</ref>. Additionally, chronic wounds can lead to decreased productivity and lost workdays for patients and caregivers. Wound management is estimated to account for over 50% of community nurse time in European studies, with patients often having three or more home health visits per week <ref type="bibr" target="#b0">[1]</ref>. The cost of reduced quality of life, combined with the economic impact, underscores the urgency of finding effective prevention and treatment strategies.</p><p>Early detection and proper management are crucial in addressing chronic wounds effectively. A multidisciplinary approach that involves wound care specialists, physicians, nurses, dietitians, and other healthcare professionals is often necessary. Preventive measures are equally important, especially for high-risk individuals. For diabetics, strict glycemic control, foot care, and regular medical check-ups can significantly reduce the risk of developing chronic wounds. Proper nutrition, maintaining a healthy weight, and regular exercise can help prevent wounds caused by arterial and venous insufficiency <ref type="bibr" target="#b11">[11]</ref>.</p><p>The fight against chronic wounds is ongoing, and innovative approaches are emerging to improve patient outcomes. Researchers are exploring advanced technologies to transform various aspects of healthcare, including chronic wound diagnosis and management, and provide clinicians with userfriendly tools to capture wound images, measure dimensions, and track healing progress over time <ref type="bibr" target="#b16">[16]</ref>. This data helps in tailoring personalized treatment plans and identifying potential complications early on. With Artificial Intelligence (AI) and/or Machine Learning (ML) algorithms, it is possible to analyze vast amounts of wound-related data, identify patterns, and assist clinicians in making informed decisions, including the early detection of infection, reducing the risk of complications <ref type="bibr" target="#b17">[17]</ref>. Telemedicine and digital health solu-tions are also being utilized to monitor and manage chronic wounds remotely, making healthcare more accessible to patients, especially those in rural or underserved areas <ref type="bibr" target="#b18">[18]</ref>.</p><p>The aim of this systematic review was to compile and analyze all relevant studies and reports published between 2013 and 2023, specifically focusing on the application of AI methods in the diagnosis of chronic wounds. The review provides a comprehensive overview of the various technological approaches employed in this period, classifying them based on their functionalities, such as tissue classification, wound area measurement, image segmentation, wound classification, and healing prediction. This classification highlights the advancements in AI-driven techniques and evaluates the outcomes achieved through these methods in supporting chronic wound diagnosis and management.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>The review adhered to the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) framework <ref type="bibr" target="#b19">[19,</ref><ref type="bibr" target="#b20">20]</ref>, ensuring a structured and transparent approach to data collection and analysis. The search spanned five major databases: ACM, IEEE, PubMed, Scopus, and Web of Science. Only studies published between 2013 and 2023 focusing on wound diagnosis through AI or ML-based methods were included. Exclusion criteria included non-English and non-Spanish articles, reviews, and those not focusing on image-or clinical data-based wound analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Search Strategy</head><p>Advanced search queries included terms such as 'wound', 'ulcer', 'skin lesion' and 'diagnosis', combined with 'artificial intelligence', 'machine learning' and other related computational methods. Broader search terms were initially used, then the first 50 results were analysed and more specific terms were incorporated into advanced database searches, using Boolean operators (OR, AND) to refine and reduce the number of results. Articles were selected based on their relevance to chronic wound diagnosis, with a specific focus on studies using RGB images or clinical patient data and computational techniques such as deep learning and supervised learning. mentation) AND (wounds OR ulcers OR "skin lesions" OR "skin damage") AND ("artificial intelligence" OR "machine learning" OR "deep learning" OR "convolutional neural network" OR "deep neural network" OR "supervised learning" OR "transfer learning" OR 'delineation OR "support vector machine" OR clustering OR "automatic detection" OR "computer assisted").</p><p>Exclusion criteria were other types of non-superficial wounds and non RGB images such as thermography, X-ray, ultrasound, computed tomography, and magnetic resonance imaging. Skin lesions such as melanomas or skin cancer and burns with interesting methods have been screened to leave as "searchable" but were not included for analysis in this systematic search. However, articles that included this type of wounds along with chronic wounds, and whose objective fell within the scope of this systematic review, were also included for evaluation. Review articles, letters to editors or editorials, non-English and non-Spanish articles or articles without full texts are excluded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Extraction and Synthesis</head><p>Key data points were systematically extracted, including the title, authors, abstract, year of publication and article type. The synthesis focused on the clinical utility of AI in wound care, detailing the ML models employed and identifying challenges related to decision support in chronic wound diagnosis.</p><p>To minimize the risk of bias, three independent reviewers assessed the included studies. One reviewer analyzed all studies, while the other two split the remaining studies equally. Each study was evaluated for inclusion, with a clear justification provided for exclusions. In cases of disagreement, the reviewers engaged in discussion until a consensus was reached, ensuring the integrity and consistency of the review process.</p><p>The final stage of the analysis involved a thorough examination of the studies and reports selected based on the established inclusion and exclusion criteria. For each study, key information was synthesized, including the type of technology employed, validation methods used, the type of chronic wound addressed, the number of samples, and the outcomes reported. During this phase, some additional articles that were not excluded in the initial screening based on title and abstract were discarded, following a more detailed review of their content.</p><p>Additionally, three articles identified from local literature, which were deemed relevant to the objectives of the systematic review, were included in the final analysis. These articles provided additional insights and were integrated into the review alongside the studies selected through the formal database search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>The systematic search identified a total of 2,791 articles, distributed across five major databases: 33 articles from ACM, 94 from IEEE, 529 from PubMed, 1,258 from Scopus, and 877 from Web of Science. After removing 1,298 duplicate articles, 1,493 unique articles were selected for further analysis. The initial screening, based on title and abstract, led to the exclusion of 1,350 articles due to differing objectives or failure to meet the inclusion and exclusion criteria. This resulted in 143 reports for in-depth reading and evaluation.</p><p>Of the 143 reports, 53 were excluded for various reasons: 4 focused on burns rather than chronic wounds, 12 had unrelated objectives, 3 utilized animal images, 24 were not related to chronic wounds (most were dermatoscopic images of skin cancer), 4 used advanced imaging techniques like computed tomography or X-ray instead of RGB images, 1 was not available in English or Spanish, 2 were review articles, and 3 did not give enough information on outcomes or techniques. After excluding these, a total of 90 articles remained. Additionally, three articles were manually added to these 90, bringing the final total to 93 articles included in this systematic review. These 93 articles comprise 38 studies and 55 reports focused on the development of specific technologies. The flow chart with the systematic research selection process is shown in Fig. <ref type="figure" target="#fig_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Characteristics of Included Articles</head><p>Of the 93 studies and final reports analyzed, 38 were based on clinical trials with real patients, and 55 were reports describing the methodology of technologies developed to support the diagnosis of various chronic wound types using images from databases. The most commonly addressed wound types include pressure ulcers (PU), diabetic foot ulcers (DFU), venous ulcers (VU), surgical wounds (SW), arterial ulcers (AU), and chronic wounds in general (CW).</p><p>Two types of samples are typically distinguished: in most cases, wound images are used, while in others, data from the patient's medical history, test results, and analyses are utilized. In a few cases, both types of samples are combined. Articles using wound images often apply algorithms based on Deep Learning (DL) techniques, sometimes incorporating Computer-Vision (CV) techniques for image processing. In contrast, studies using patient data tend to apply ML algorithms. One of the primary objectives of this systematic review is to identify and categorize the key methods used to support chronic wound diagnosis through AI or ML. The identified methods can be classified into several categories: Wound tissue classification techniques Section "Wound Tis sue Classification", wound measurement Section "Wound Measurement", wound segmentation Section "Wound Seg mentation", class prediction (often focused on different etiologies) Section "Wound Classification", and wound healing prediction or risk indicators Section "Wound Healing". Notably, some articles were found to employ more than one of these tasks, demonstrating the versatility of AI and/or ML in addressing multiple aspects of wound diagnosis and management. Figures <ref type="figure">2</ref> and<ref type="figure">3</ref> show the distribution of tasks among the selected studies and reports, respectively. In total, 6 articles (0 studies, 6 reports) address tissue classification, 6 articles (4 studies, 2 reports) focus on wound measurement, 19 articles (9 studies, 10 reports) examine wound segmentation, 35 articles (11 studies, 24 reports) classify wounds mostly by etiology, and 13 articles (10 studies, 3 reports) predict wound healing. Additionally, 14 articles (4 studies, 10 reports) employ multiple previous tasks in their analyses Section "Multiple Methods".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Quality Assessment</head><p>A systematic evaluation was conducted to assess the methodological quality of 93 studies using the QUADAS-2 framework <ref type="bibr" target="#b21">[21]</ref>. Although originally designed for clinical trials, QUADAS-2 evaluates the quality of methods and data related to diagnostic tools, making it applicable to studies that develop or validate diagnostic models, such as those employing machine learning or imaging technologies <ref type="bibr" target="#b22">[22]</ref>. Many of the reviewed articles involved diagnostic processes where models were tested for accuracy, functioning similarly to diagnostic tools in clinical trials.</p><p>The assessment included adaptations to align with the nature of non-clinical diagnostic studies. The Patient Selection domain was adjusted to evaluate the representativeness of datasets and the inclusion or exclusion criteria for data Fig. <ref type="figure">2</ref> Task distribution between selected studies points, rather than focusing solely on patient-level factors. In the Index Test domain, the methodological rigor of the diagnostic models, including algorithms and neural networks, was examined, particularly their training and validation protocols. The Reference Standard domain was evaluated based on the quality and reliability of annotations or ground truth data, even when not derived from clinical settings. Flow and Timing was interpreted to assess the overall data handling, including exclusions and the completeness of the analysis process (Fig. <ref type="figure">4</ref>).</p><p>In the domain of Patient Selection, most studies demonstrated a low risk of bias due to the use of clear inclusion criteria and appropriate sampling. However, around 25% showed moderate or high risk, often because of limited diversity in datasets or unrepresentative populations. Studies relying on datasets from single institutions or specific regions lacked broader demographic and clinical applicability. For the Index Test, the majority of studies exhibited low risk of bias, with clear documentation of machine learning methodologies and robust validation. Nevertheless, a minority had moderate risk due to inadequate blinding or reliance on pretrained models without testing on independent datasets.</p><p>The Reference Standard domain had the highest proportion of moderate-to-high risk of bias. Many studies failed to adequately describe how ground truth labels were generated, with few employing blinded or independent expert validation. The absence of inter-rater reliability metrics or external validation raised concerns about the consistency and robustness of the reference standards. Flow and Timing presented the lowest risk of bias, with most studies showing well-documented workflows and minimal exclusions. However, some studies lacked clarity on the timing between data acquisition and reference standard application, potentially introducing bias.</p><p>Overall, studies utilizing large, diverse datasets with rigorous validation processes demonstrated consistently lower risk of bias. Conversely, innovative studies, such as those integrating 3D modeling or portable devices, often lacked robust external validation, contributing to moderate concerns, particularly in the Reference Standard domain. Across all domains, common limitations included insufficient diver-sity in patient demographics and a reliance on single-center datasets, which hindered generalizability.</p><p>Future research should focus on expanding datasets to ensure broader geographic, demographic, and clinical variability. This would enhance the generalizability of findings and reduce biases related to unrepresentative datasets. Ground truth labeling processes should incorporate blinded evaluations and include inter-rater reliability metrics to improve the reliability of the Reference Standard. Models should undergo external validation using independent, realworld datasets to ensure robustness and clinical applicability. Additionally, providing detailed descriptions of dataset characteristics, patient selection criteria, and timing protocols is crucial to enhance transparency, reproducibility, and comparability across studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation Metrics</head><p>The AI methods reviewed in this study employ a variety of evaluation metrics to assess their performance across different functionalities in chronic wound diagnosis. Most of these metrics are derived from the confusion matrix, which categorizes model predictions into true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN) <ref type="bibr" target="#b23">[23]</ref>. These metrics are summarized in Table <ref type="table" target="#tab_0">1</ref>.</p><p>Among these metrics, the AUC (Area Under the Curve) and the Receiver Operating Characteristic (ROC) curve are particularly significant. The ROC curve visually represents the trade-off between sensitivity (True Positive Rate) and the False Positive Rate (1-specificity) across various classification thresholds. It is used to evaluate the model's ability to distinguish between classes. A perfect model achieves a curve that passes through the top-left corner (True Positive Rate = 1, False Positive Rate = 0), while a random classifier produces a diagonal line. The AUC is a scalar summary of the ROC curve, quantifying the overall discriminative performance of the model. It is particularly beneficial for imbalanced datasets, as it evaluates the model's performance across all thresholds rather than relying on a single threshold. The AUC is directly related to the confusion matrix because it reflects the balance between true positives, false positives, true negatives, and false negatives. However, it does not depend on a fixed decision threshold, making it more comprehensive <ref type="bibr" target="#b25">[25]</ref>.</p><p>While these metrics are traditionally used in binary classification tasks, they are also extended to assess functionalities involving numeric outputs or multi-class tasks, such as wound area measurement and image segmentation. For example, wound area measurement uses regressionbased metrics like Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE) to quantify the accuracy of predicted wound areas relative to ground truth measurements. For image segmentation, metrics such as the Dice Similarity Coefficient (DSC) and Intersection over Union (IoU) are employed to evaluate the overlap between predicted and actual segmented wound areas. These metrics provide a nuanced evaluation of segmentation algorithms, which is critical for tasks requiring precise delineation of wound boundaries <ref type="bibr" target="#b26">[26]</ref>.</p><p>In addition to these standard performance metrics, Intraand inter-rater reliability are crucial for ensuring the quality of ground truth data in AI models. Intra-rater reliability measures the consistency of a single rater's judgments over time, while inter-rater reliability evaluates agreement between multiple raters. Both are essential for validating datasets, particularly for subjective tasks like wound segmentation or classification. High reliability ensures consistent and unbiased annotations, reducing noise in training data and improving AI model performance. These metrics are typically quantified using tools such as the Intraclass Correlation Coefficient (ICC), which measures agreement in continuous data like wound area or volume and Cohen's Kappa or Fleiss' A balanced measure for binary classification tasks, especially for imbalanced datasets, providing a more holistic assessment of prediction quality <ref type="bibr" target="#b24">[24]</ref>   Kappa, which evaluate categorical agreement, such as wound classification into tissue types <ref type="bibr" target="#b27">[27]</ref>.</p><p>By employing these diverse metrics, the AI models reviewed in this study can be evaluated comprehensively across a wide range of chronic wound diagnosis tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Wound Tissue Classification</head><p>Wound tissue classification tasks focus on identifying different types of tissues within wounds (e.g., necrotic, granulation) using machine learning and deep learning approaches, such as Convolutional Neural Networks (CNNs) and Support Vector Machines (SVMs) (Table <ref type="table" target="#tab_1">2</ref>).</p><p>Mukherjee et al. explored the use of color and textural features combined with ML algorithms to classify granulation, necrotic, and slough tissues in chronic wounds. The images were segmented using fuzzy divergence-based thresholding, and pixel prediction was validated through statistical methods such as Kappa statistics. The results demonstrated that a SVM with a third-order polynomial kernel achieved high accuracy rates for classifying different tissue types, with accuracies of 86.94% for granulation, 90.47% for slough, and 75.53% for necrotic tissue. <ref type="bibr" target="#b28">[28]</ref>. Similarly, the research from Veredas et al. used a CV approach combined with ML models to classify tissue types in wounds. By applying the k-means clustering algorithm for image segmentation and comparing several ML models, including neural networks (NN), SVM, and random forests (RF), the study achieved high performance rates. The accuracy rates varied depending on the model, with NN achieving 81.87%, RF at 87.37%, and SVM at 88.08% <ref type="bibr" target="#b31">[31]</ref>.</p><p>Ramachandram et al. employed a DL approach to automatically segment four key tissue types in chronic wounds: epithelial, granulation, slough, and eschar. Using an encoderdecoder model based on EfficientNetB0 architecture, the model was trained on a large dataset of 17,000 anonymized wound images. The segmentation model achieved high intersection-over-union (IoU) scores for wound segmentation (0.8644) and tissue segmentation (0.7192). While the model performed well in detecting slough and eschar (F1scores of 0.731 and 0.802, respectively), it struggled with epithelial tissue, achieving a low precision and recall, resulting in an F1-score of 0.253 <ref type="bibr">[29]</ref>. Zahia et al. report focused on pressure injuries, utilizing a nine-layer CNN for the segmentation of granulation, slough, and necrotic tissues. The model achieved a high overall accuracy of 92.01%, with a weighted Dice Similarity Coefficient (DSC) of 91.38%. The precision per class was particularly high for granulation tissue (97.31%) and necrotic tissue (96.59%), though slough tissue had a lower precision (77.90%) <ref type="bibr" target="#b30">[30]</ref>.</p><p>Using more advanced technology, Begoña et al. developed a multi-pathway 3D CNN called DeepMedic to segment and classify tissue types in pressure ulcers, including slough, granulation, and necrotic eschar. The model achieved strong performance metrics, with an average Area Under the Curve (AUC) of 95%, a DSC of 92%, and a Percentage Area Distance (PAD) of 10% <ref type="bibr" target="#b32">[32]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Wound Measurement</head><p>Techniques of wound measurement aim to quantify wound characteristics like area, depth, and volume. Methods typically involve image processing models, including Mask R-CNN, to automate the measurement process, ensuring accuracy compared to manual assessments (Table <ref type="table" target="#tab_2">3</ref>).</p><p>Mohammed et al. compared the time efficiency of an AIbased wound assessment tool (Swift Medical) with manual methods in 91 patients with 115 wounds, including VU, DFU and SW. The results showed that the AI tool significantly reduced the time required for wound assessment, completing tasks in an average of 62 s. While the specific algorithms behind the tool were not detailed, the results suggest that AI-based wound assessment tools can streamline clinical workflows <ref type="bibr" target="#b9">[9]</ref>. Similarly, in the study of Chan et al., the CARES4WOUNDS (C4W) system, an AI-enabled mobile application for wound imaging, was validated for diabetic foot ulcers. The study evaluated the intra-and interrater reliability of the tool by comparing its measurements with traditional manual methods across 547 images from 28 patients. The C4W system demonstrated high reliability, with intra-rater reliability ranging from 0.933 to 0.994 and interrater reliability for wound length measurements at 0.947 <ref type="bibr" target="#b33">[33]</ref>. Simpson et al. measured digital ulcers in systemic sclerosis (SSc) using two digital planimetry methods: ellipse and freehand Region of interest (ROI). The study, which involved 107 finger lesions from 36 patients, reported high intra-and interrater reliability. However, it relied on manual segmentation, which could introduce variability. The method involved using a calibrator to detect pixels and compute distances but did not fully explain how the measurement was performed <ref type="bibr" target="#b35">[34]</ref>.</p><p>Ferreira et al. implemented basic CV techniques such as grayscale conversion, Canny detection, and OpenCV for wound area measurement in 10 images. This method showed higher error rates when implemented on a desktop machine compared to a mobile device. The study highlighted technical challenges such as metadata loss, indicating that more advanced technology is needed for accurate and functional wound area measurement <ref type="bibr" target="#b36">[35]</ref>.</p><p>Foltynski et al. implemented an internet-based service for automatic wound area measurement using U-Net CNN applied to DFU. The system achieved high performance, with a DSC of 90.9%, an IoU of 83.9%, an accuracy of 99.3%, and specificity of 99.6%. However, the system struggled with detecting wound margins in cases of irregular edges, which suggests room for improvement in edge detection for chronic wounds <ref type="bibr" target="#b37">[36]</ref>. Lastly, the Niri et al. study aimed to improve  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Wound Segmentation</head><p>Segmentation methods use algorithms to identify and outline wound boundaries within an image. Models such as U-Net and Mask R-CNN are commonly employed to isolate wound regions for further analysis or measurement.</p><p>Several articles focus on wound localization and segmentation as a primary step for automating wound care. Various CNN architectures were compared in the context of wound segmentation (Table <ref type="table" target="#tab_3">4</ref>). Ohura et al. demonstrated that U-Net with a VGG16 encoder pre-trained on ImageNet produced the best results for DFU and VU, with an AUC of 0.997, specificity of 0.943, and sensitivity of 0.993. U-Net was noted for its practical application due to faster segmentation speeds compared to other architectures such as SegNet and LinkNet <ref type="bibr" target="#b39">[38]</ref>. Also, in a comparative study <ref type="bibr" target="#b40">[39]</ref> of DL-based segmentation methods, including U-Net, ConvNet, DeepLab, and Fully Convolutional Networks (FCN), the U-Net model performed well across varying training set sizes, maintaining segmentation performance with a Matthews correlation coefficient (MCC) in the range of 0.768-0.84 even with reductions in the training set size. Similarly, <ref type="bibr" target="#b41">[40]</ref> demonstrated that Mask-RCNN achieved the highest precision in chronic wound segmentation, with 94.3% precision and a recall of 86.4%. In contrast, U-Net showed superior recall, achieving 91.29%, and slightly lower precision of 91.01%. Huang et al. applied three deep neural networks, including Fast R-CNN ResNet101 and Inception, to identify and refine wound boundaries using GrabCut and SURF algorithms. Among the trained models, ResNet101_Kitti had the highest precision (mAP of 87), while ResNet101_fgvc was the fastest (speed of 395ms) <ref type="bibr" target="#b42">[41]</ref>.</p><p>Novel techniques such as fuzzy spectral clustering were applied to wound region delineation and achieved an accuracy of 91.5% with a DSC of 86.7% on a set of 70 chronic wound images <ref type="bibr" target="#b43">[42]</ref>. Another innovative approach <ref type="bibr" target="#b44">[43]</ref> involved a wound segmentation network that enhanced location information, yielding a mean IoU of 86.47% and a precision of 95.03% from 950 images. Work from Gholami et al. compared three edge-based algorithms for chronic wound segmentation found that the Livewire (Intelligent Scissors) technique outperformed others, achieving mean values of 97.08% accuracy, 99.68% sensitivity, and 96.67% specificity across 26 images from 15 subjects, along with excellent Jac-card index and DSC scores <ref type="bibr" target="#b45">[44]</ref>. In another study <ref type="bibr" target="#b46">[45]</ref>, the automatic measurement of PU using SVM and the GrabCut method showed an accuracy of 96%, sensitivity of 94%, and a specificity of 97% across 105 images from the public MEDE-TEC database. Similarly, a framework <ref type="bibr" target="#b47">[46]</ref> using associative hierarchical random field (AHRF) for foot ulcer detection achieved specificity rates above 95% and sensitivity above 77% in tracking 15 patients over two years. Novel techniques of wound measurements are summarized in Table <ref type="table" target="#tab_4">5</ref>.</p><p>Other studies incorporated hybrid techniques to improve segmentation accuracy (Table <ref type="table">6</ref>). For example, Heras-Tang et al. developed a method combining logistic regression (LR), DBSCAN clustering, and morphological operations for DFU segmentation achieved the best Jaccard index of 0.81, accuracy of 94%, and F1 score of 0.88 with the LR model on a dataset of 140 images <ref type="bibr" target="#b48">[47]</ref>. Another study <ref type="bibr" target="#b49">[48]</ref> using semi-supervised active learning and transfer learning demonstrated high efficiency in wound segmentation tasks. After fewer than 50 training epochs, a CNN-based architecture pre-trained on ImageNet achieved a stable DSC of 0.95, showing effective performance on a dataset of over 1,500 chronic wound images.</p><p>Additionally, color space selection played a crucial role in segmentation accuracy in several articles (Table <ref type="table" target="#tab_5">7</ref>). With the YDbDr color space, Yadav et al. obtained the highest contrast and accuracy for wound and non-wound region segmentation using k-means and fuzzy c-means clustering <ref type="bibr" target="#b50">[49]</ref>. Atisattapong et al. assessed the use of Particle Swarm Optimization (PSO) combined with binary image segmentation to optimize thresholding for chronic wound assessment, achieving improved segmentation in 46% of cases when compared to the traditional Otsu method, though it provided limited insights overall <ref type="bibr" target="#b51">[50]</ref>. Dhane et al. utilized spectral clustering for unsupervised segmentation of lower extremity wound beds, demonstrating a segmentation accuracy of 86.73%, with positive predictive values of 91.80% and sensitivity of 89.54%, surpassing k-means and fuzzy c-means methods <ref type="bibr" target="#b52">[51]</ref>. Lu et al. introduced a CNN-based method that included a fast level set model for intensity correction and color adjustments, reporting a 3% improvement in average accuracy over traditional methods when tested on 300 chronic wound images <ref type="bibr" target="#b53">[52]</ref>. Lastly, an approach <ref type="bibr" target="#b54">[53]</ref> employing statistical color models for wound area detection achieved a high AUC of 0.9426 and accuracy of 87.77% across 435 images from home-care patients.</p><p>Finally, approaches have been identified for real-time CW detection on mobile devices (Table <ref type="table" target="#tab_6">8</ref>). A report <ref type="bibr" target="#b55">[54]</ref> using MobileNet and Inception-V2 models demonstrated varying performance in terms of speed and accuracy. MobileNet was superior in terms of speed and model size, but Faster R-CNN with Inception-V2 showed better accuracy in localizing DFU, achieving an average precision of 91.8% and indicating that real-time performance considerations may require </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Wound Classification</head><p>These techniques classify wounds based on their type (e.g., diabetic, venous, pressure ulcers) by analyzing wound features through ML like SVM or RF. They help in understanding wound etiology and tailoring treatment plans.</p><p>Several models have been developed to improve wound classification, particularly for diabetic foot DFU, PU, and other chronic wounds (Table <ref type="table" target="#tab_7">9</ref>). Goyal et al. introduced a CNN to distinguish between healthy and DFU-affected skin. It compared DFUNet to LeNet, AlexNet, and GoogLeNet, achieving a sensitivity of 93.4% and an AUC of 0.962 <ref type="bibr" target="#b58">[57]</ref>. Another report <ref type="bibr" target="#b59">[58]</ref> proposed a network architecture that increased network width while maintaining depth for effective DFU classification. The model, trained on 754 DFU images, achieved 95.4% precision, 93.6% recall, and 94.5% F1-score, showcasing its robustness. An article <ref type="bibr" target="#b60">[59]</ref> focused on ischemia and infection classification in DFUs, comparing models like InceptionV3, ResNet50, and Incep-tionResNetV2. Ensemble CNN models achieved an accuracy of 90% for ischemia and 73% for infection, outperforming traditional ML algorithms. This concept was further expanded by Xu et al., which introduced a Class Knowledge Bank (CKB) approach leveraging models like ResNet, Effi-cientNet, and DeiT to classify DFU infection and ischemia. The CKB-DeiT-B-D model achieved an F1-score of 78.20% and an AUC of 84.78%, surpassing other models in performance <ref type="bibr" target="#b61">[60]</ref>. Beyond DFU classification, Anisuzzaman et al. combined wound images and location information using VGG16, ResNet50, and LSTM models to classify multiple wound types including DFUs, PUs, VUs, and SWs. This approach attained the highest accuracy of 86.67% on the Medetec dataset when using a VGG19 + MLP combination <ref type="bibr" target="#b62">[61]</ref>. Ahsan et al. employed architectures such as AlexNet, VGG16, and ResNet50 on the DFU2020 dataset, achieving a maximum accuracy of 99.49% for ischemia and 84.76% for infection classification with ResNet50 <ref type="bibr" target="#b63">[62]</ref>. In another study <ref type="bibr" target="#b64">[63]</ref>, introduced the CNN_GLCMNet model, which combined GLCM features with deep learning, achieving 97.43% accuracy on a dataset of 756 images. Protik et al. presented DFINET, a 22-layer CNN that attained 91.98% accuracy on 5,890 images, demonstrating its effectiveness in infection detection <ref type="bibr" target="#b65">[64]</ref>. In addition to segmentation, a study <ref type="bibr" target="#b66">[65]</ref> integrated wound classification techniques using Mask-RCNN for the classification of PUs in different stages showed an overall classification accuracy of 92.6% across 969 images, with F1 scores for stages 1-4 of PUs ranging from 0.842 to 0.944. Additionally, Das et al. utilized ResNet for classifying ischemia and infection, achieving an impressive AUC of 0.9968 for ischemia detection <ref type="bibr" target="#b67">[66]</ref>.</p><p>The exploration of hybrid models further enhanced classification accuracy in wounds (Table <ref type="table" target="#tab_0">10</ref>). Alzubaidi et al. assessed four hybrid CNN models, achieving a precision of 97.3% and a recall of 94.5% on 754 images <ref type="bibr" target="#b68">[67]</ref>. Al-Garaawi et al. introduced a fusion-based approach that combined hand-crafted features like Gabor and Histogram of Oriented Gradients (HOG) with deep features extracted from a GoogleNet CNN. This approach improved AUC scores to 0.97 for ischemia detection and 0.81 for infection classification <ref type="bibr" target="#b69">[68]</ref>. The report <ref type="bibr" target="#b70">[69]</ref> utilized an ensemble CNN (AlexNet) for categorizing wound images, achieving an average classification accuracy of 94.28% for binary and 91.9% for multiclass problems across 400 images. Furthermore, Liu et al. utilized EfficientNet, which achieved 99% accuracy for ischemia and 98% for infection classification, showcasing the effectiveness of this architecture <ref type="bibr" target="#b71">[70]</ref>.</p><p>Several studies applied traditional ML techniques to address wound classification (Table <ref type="table" target="#tab_8">11</ref>). Hu et al. used decision trees (DT), LR, and RF, with RF demonstrating an AUC of 0.864 across 11,838 records <ref type="bibr" target="#b72">[71]</ref>. Sotoodeh et al. applied LR, RF and NN to detect and classify PU based on nurse notes in the MIMIC-III dataset. The analysis on of 3,589 cases used the Scispacy tool for named entity recognition and NegEx for negation detection. RF achieved the highest AUC (95%), making it the best-performing model for interpreting clinical notes related to pressure ulcers <ref type="bibr" target="#b73">[72]</ref>. In Moon et al. study, DT analysis revealed significant risk factors for PU development, achieving an accuracy of 80.4% <ref type="bibr" target="#b74">[73]</ref>. Additionally, Silva et al. employed a K-means clustering approach to classificate patients into high-and low-risk groups based on self-care behaviors, foot care habits, and social conditions, and achieving 97% accuracy in identifying high-risk patients based on a dataset of 153 individuals <ref type="bibr" target="#b75">[74]</ref>.</p><p>Specialized models have been developed to target specific classifications within wound management (Table <ref type="table" target="#tab_1">12</ref>). Huang et al. presented a CNN model that classified multiple wound types, achieving 96% accuracy in the venous ulcer classification task using 2,149 images <ref type="bibr" target="#b76">[75]</ref>. The study <ref type="bibr" target="#b77">[76]</ref> integrated global foot features with local wound features, achieving 95.78% accuracy on 1,211 DFU images. Explainable AI techniques have also been applied in chronic wound classification. <ref type="bibr">Sarp</ref>  The algorithm achieved a sensitivity of 82.4% and specificity of 100% in identifying necrosis and its type (black or white), emphasizing the importance of specialized algorithms for wound-specific tasks <ref type="bibr" target="#b79">[78]</ref>. Moreover, Alzubaidi et al. explored transfer learning in DFU classification, achieving a remarkable F1-score of 97.6% with a dataset of 1,200 images, emphasizing the effectiveness of domain-specific approaches <ref type="bibr" target="#b80">[79]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>et al. utilized XAI tools on a dataset</head><p>Several studies harnessed YOLO-based models for effective wound detection and classification (Table <ref type="table" target="#tab_2">13</ref>). One article <ref type="bibr" target="#b81">[80]</ref> achieved a mAP of 76.9% on over 1,000 images, showcasing its efficacy in detecting pressure ulcers. Amin et al. combined CNN for classification and YOLOv2-DFU for localization, achieving 99% accuracy in a dataset comprising ischemia and infection cases <ref type="bibr" target="#b82">[81]</ref>. In addition, Husers et al. employed YOLOv5 models to classify DFU and VU, with the YOLOv5m6 model achieving a precision of 0.942 and recall of 0.837 on 885 images <ref type="bibr" target="#b83">[82]</ref>.</p><p>Further contributions in the field include a report <ref type="bibr" target="#b84">[83]</ref> which compared a modified ResNet with SVM, RF, and Gradient Boosted Decision Trees (GBDT), achieving an AUC of 83.3% with ResNet, outperforming SVM (44.4%), random forest (67.1%), and gradient boosting classifier (66.9%) for wound infection detection on a dataset of 480 images. Another article <ref type="bibr" target="#b85">[84]</ref> explored factorization-based segmentation for pressure and venous ulcers using MLP, SVM, RF, and NB, with MLP achieving the highest accuracy (83.1%) compared to SVM (79.7%), RF (79.7%), and Naïve Bayes (72.9%). In <ref type="bibr" target="#b86">[85]</ref> utilized transfer learning from InceptionV3, ResNet50, and VGG16 to classify ulcers, achieving a sensitivity of 97% with VGG16, significantly outperforming dermatologists (sensitivity 72.7% for experts, 45.5% for juniors). Additionally, the study <ref type="bibr" target="#b87">[86]</ref>   <ref type="bibr" target="#b91">[90]</ref>. The report of the articles are summarised in the Table <ref type="table" target="#tab_10">14</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Wound Healing</head><p>These methods predict wound healing progress or identify risks for delayed healing based on factors like tissue health or wound size. ML algorithms are used to assess the likelihood of healing or complications, aiding clinical decision-making. Notably, the evaluation of wound healing progress in chronic wounds often relies on the predictive scar factor, which is methodologically based on weekly assessments over 4 consecutive weeks. This approach is essential for establishing accurate healing metrics and for providing comparative parameters that allow AI tools to optimize their learning and prediction capabilities <ref type="bibr" target="#b92">[91]</ref>.</p><p>In the field of DL, several studies have explored the application of CNNs for wound assessment (Table <ref type="table" target="#tab_4">15</ref>). A Reduced ResNet-18 model was employed in <ref type="bibr" target="#b93">[92]</ref> to detect granulation tissue in DFU, demonstrating an IoU rate above 0.5 for identifying tissue growth. Similarly, a DenseNet CNN framework with patch-based attention was used in <ref type="bibr" target="#b94">[93]</ref> to assess multiple wound attributes, achieving accuracy and F1 scores above 0.8. Another study <ref type="bibr" target="#b95">[94]</ref> introduced the Semi-Supervised PMG EfficientNet architecture, improving wound assessment accuracy to 90% by augmenting the WoundNet dataset with a Progressive Multi-Granularity mechanism. In self-care, a smartphone-based system allowed patients to assess surgical wounds by using a variety of classifiers, such as CART and Naïve Bayes, reaching over 90% accuracy in wound state evaluation <ref type="bibr" target="#b96">[95]</ref>. In another study <ref type="bibr" target="#b97">[96]</ref>, smartphone and tablet cameras were used to capture DFU images for healing prediction, employing ResNet50 for feature extraction and RF and SVM for classification. The study demonstrated higher AUROC values (0.734) when combining all features and showed improved performance when using handcrafted imaging features (0.760-0.794) compared to clinical features alone. Also, a large-scale AI model, AutoTrace, for wound healing prognosis, was developed by Gupta et al.based on over 2 million wound evaluations, achieving an IoU score of 0.86 and an 8-13% improvement over tools like the PUSH and the BWAT. While PUSH is specific to pressure injuries and BWAT is broader, covering venous, diabetic, and arterial ulcers, both have limitations in addressing diverse wound types <ref type="bibr" target="#b16">[16]</ref>.</p><p>On the ML side, a variety of models were used to predict wound healing outcomes and risk factors (Table <ref type="table" target="#tab_0">16</ref>). Naïve Bayes (NB) classifiers combined with serial wound characteristics significantly improved the prediction of surgical site infections (SSI) compared to baseline risk factors <ref type="bibr" target="#b98">[97]</ref>. Additionally, ML algorithms, such as SVM, NB, RF, were employed in predicting hard-to-heal DFUs <ref type="bibr">[98]</ref>, with the NB model achieving the best results (AUC 0.864). In 123 another study <ref type="bibr" target="#b99">[99]</ref>, ML classifiers generated actionable decisions for chronic wound care, with XGBoost achieving 81% accuracy when combining visual and textual data. Other predictive models like LR, RF, and GBDT were used to forecast wound healing times in large datasets <ref type="bibr" target="#b100">[100]</ref>, yielding AUCs around 0.85 for 4-, 8-, and 12-week healing probabilities.</p><p>Another study <ref type="bibr" target="#b14">[14]</ref> utilized LR and RF classifiers for a risk stratification analysis of DFU and amputation, incorporating both socioeconomic and medical data from over 246,705 patients with diabetes. It identified significant risk factors such as cardiovascular disease, peripheral artery disease, and neuropathy. Additionally, the study reported an inverse correlation between disposable income and the risk of DFU and amputation. However, while the study integrates socioeconomic factors with medical data, the exact computational interaction between these variables and the AI models is not explicitly detailed. Finally, hybrid approaches combining structured and unstructured data were used to enhance predictive accuracy (Table <ref type="table" target="#tab_0">16</ref>). For example, a study <ref type="bibr" target="#b101">[101]</ref> on wound infectionrelated hospitalizations utilized LR, RF, and ANN, showing significant improvements in predictive performance when both structured OASIS-C data and unstructured clinical notes were integrated. Similarly, a GBDT model was developed for rapid identification of slow-healing wounds, achieving an AUC of 0.842 <ref type="bibr" target="#b102">[102]</ref>, highlighting the importance of wound characteristics and patient care status in predictive modeling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multiple Methods</head><p>Several studies utilized CNN and related architectures to segment wound tissues and assess wound characteristics (Table <ref type="table" target="#tab_11">17</ref>). For example, Blanco et al. used a Reduced ResNet-18 model for identifying granulation tissue in DFUs, showing that IoU rates exceeded 0.5 across 219 images from 100 patients <ref type="bibr" target="#b103">[103]</ref>. Similarly, Zahia et al. employed Mask R-CNN with ResNet backbones on a dataset of 210 wound images, achieving high DSC (0.83) and precision (0.87) for wound segmentation, with low errors in depth estimation <ref type="bibr" target="#b104">[104]</ref>. The Comprehensive Wound Image Assessment by Chang et al. also applied DeepLabV3, reaching impressive accuracy for both tissue classification and wound segmentation (precision 0.9915) on over 2800 images <ref type="bibr" target="#b105">[105]</ref>. Similarly, Chino et al. employed an encoder/decoder neural network to segment venous and AU across 446 images. The model achieved a DSC score above 90% for wound segmentation, outperforming QTDU and DeepLabv3+ by up to 16%. Additionally, it estimated the wound area with a relative error of 12.1% <ref type="bibr" target="#b106">[106]</ref>. Other efforts also leveraged DenseNet CNN frameworks with patch-based attention, as demonstrated by Chakraborty et al., where the model successfully classified different wound attributes in 1639 images with F1 scores exceeding 0.8 for DFU, PU, VU and SW <ref type="bibr" target="#b107">[107]</ref>. Some studies integrated semi-supervised learning techniques or hybrid architectures to handle limited data availability or augment existing datasets (Table <ref type="table" target="#tab_6">18</ref>). Da Silva et al. proposed a semi-autonomous YOLO V2 CNN model to classify wound tissues using 1,194 images, although it achieved a relatively modest mAP of 21.32% <ref type="bibr" target="#b108">[108]</ref>. On the other hand, Liu et al. compared U-Net and Mask R-CNN for PU segmentation, where U-Net achieved significantly higher segmentation accuracy (DSC of 0.8448) <ref type="bibr" target="#b109">[109]</ref>. Furthermore, Rajathi et al. combined CNNs with active contour techniques to classify varicose ulcer tissues with remarkable accuracy (99.55%) <ref type="bibr" target="#b110">[110]</ref>. Also, in <ref type="bibr" target="#b111">[111]</ref> Mask R-CNN was validated using 330 images to segment wounds compared to expert clinicians' assessments. It achieved higher processing speed, reproducibility, and interclass correlation coefficient (ICC) values of 0.77 for software-based analysis compared to 0.34 for ruler-based methods. Intra-rater reliability was excellent, with ICC values of 0.99.</p><p>ML models were also applied to predict wound healing outcomes and risk factors (Table <ref type="table" target="#tab_12">19</ref>). For instance, Chairat et al. evaluated several AI models for tissue segmentation, achieving a mean IoU of 0.6964 for wound area segmentation and moderate performance for epithelialization (IoU of 0.3957) <ref type="bibr" target="#b112">[112]</ref>. Zhao et al. focused on classifying wound depth and granulation tissue grades in diabetic wounds, achieving 84.6% accuracy in both areas <ref type="bibr" target="#b113">[113]</ref>. Hsu et al. used an SVM-based infection assessment system to identify wound infections from 293 images, reporting an accuracy of 89.04% <ref type="bibr" target="#b114">[114]</ref>.</p><p>Some studies focused on utilizing ML to assist in clinical decision-making regarding wound management (Table <ref type="table" target="#tab_12">19</ref>). Nagata et al. developed classifiers such as SVM and RF to categorize wound segments from 31 images, reporting higher performance from the SVM model (Jaccard index of 68%) <ref type="bibr" target="#b115">[115]</ref>. Similarly, Reifs et al. applied various CNN models (including ResNet50) for wound measurement, demonstrating high inter-rater reliability (0.98) and low median relative errors (2.907) in wound contour detection <ref type="bibr" target="#b116">[116]</ref>.</p><p>Finally, the integration of mobile technologies for wound care was also explored (Table <ref type="table" target="#tab_12">19</ref>). Zoppo et al. tested an AIpowered device called the Wound Viewer on 150 patients with various chronic wounds (DFU, PU), achieving 97% accuracy in wound bed classification <ref type="bibr">[117]</ref>. This underscores the potential of AI-driven devices for remote wound monitoring and management.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>The reviewed studies on wound tissue classification highlight various ML and DL approaches, with a focus on classifying different tissue types in chronic wounds, such as granulation, necrotic, and slough tissues. <ref type="bibr">Mukherjee</ref>  Wound measurement techniques aim to quantify wound characteristics such as area, depth, and volume through automated image processing models, typically using methods like Mask R-CNN. These approaches ensure accuracy compared to manual assessments and improve clinical workflows. For instance, Mohammed et al. demonstrated that an AI-based tool, Swift Medical, reduced wound assessment time significantly, completing tasks in an average of 62 s <ref type="bibr" target="#b9">[9]</ref>. Chan et al. validated the CARES4WOUNDS system for diabetic foot ulcers, showing high intra-and inter-rater reliability in wound measurement <ref type="bibr" target="#b33">[33]</ref>. Simpson et al. evaluated digital planimetry methods for measuring systemic sclerosis ulcers, noting high reliability despite using manual segmentation, which could introduce variability <ref type="bibr" target="#b35">[34]</ref>. In simpler approaches, Ferreira et al. employed basic computer vision techniques like grayscale conversion and Canny detection, but encountered higher error rates due to technical limitations, suggesting the need for more advanced methods <ref type="bibr" target="#b36">[35]</ref>. In contrast, Foltynski et al. achieved high accuracy using a U-Net CNN for diabetic foot ulcers, though edge detection in chronic wounds remained challenging <ref type="bibr" target="#b37">[36]</ref>. Niri et al. further improved wound segmentation through a DL-based method, utilizing multi-view data augmentation and 3D surface modeling to achieve significantly better DSC and IoU scores <ref type="bibr" target="#b38">[37]</ref>. Overall, these results highlight the growing role of AI and/or DL in wound assessment, with significant improvements in time efficiency, accuracy, and measurement quality. Accurate wound measurement is essential for monitoring wound healing progress and adjusting treatment plans accordingly. Automated systems that reduce assessment time are particularly beneficial in high-volume settings, improving efficiency and ensuring consistent, real-time monitoring of wound status. This can lead to more timely interventions, reducing the risk of complications such as infection or non-healing ulcers, which are common in chronic conditions like diabetes and venous insufficiency. However, challenges such as handling irregular wound edges, metadata loss, and reliance on manual methods in some cases suggest areas for further technological development.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>et al. combined color</head><p>Wound segmentation methods focus on accurately identifying and outlining wound boundaries in images using algorithms like U-Net, Mask R-CNN, and YOLOv3. These models isolate wound regions to assist in further analysis and measurement, improving the efficiency and precision of wound care. Studies such as Anisuzzaman et al. demonstrated that YOLOv3 outperforms other models in wound localization, achieving high precision with a mAP score of 0.97 <ref type="bibr" target="#b57">[56]</ref>. Other methods, like SVM combined with the Grab-Cut algorithm, achieved impressive sensitivity and specificity for pressure ulcer segmentation, while U-Net has been highlighted for its speed and efficiency in chronic wound segmentation tasks. Comparative studies of deep learning models showed that Mask R-CNN provides the highest precision for wound segmentation, while U-Net excels in recall. Hybrid techniques, such as combining LR with clustering, have also been effective in improving segmentation accuracy, while novel approaches like fuzzy spectral clustering and 3D surface modeling show significant potential for enhancing wound boundary detection. Additionally, color space selection and methods like Particle Swarm Optimization have been explored for improving segmentation accuracy, particularly in difficult cases. Real-time detection of wounds, such as diabetic foot ulcers, on mobile devices is another promising area, with models like MobileNet showing great potential for balancing speed and accuracy in clinical settings. Overall, wound segmentation enhances the precision of wound assessments, helping clinicians make more informed decisions about treatment strategies, such as whether a wound is infected or healing as expected. More accurate segmentation of wound boundaries also facilitates the calculation of wound area, depth, and volume, which are crucial parameters for assessing wound healing and determining the appropriate care, including whether advanced treatments like skin grafts or negative pressure wound therapy are needed.</p><p>Wound classification techniques utilize machine learning models such as SVM, RF, and CNNs to categorize wounds based on type, such as DFU, VU and PU. Several studies have developed advanced models to improve classification accuracy. For example, Goyal et al. used a CNN-based approach for DFU classification, achieving high sensitivity and AUC <ref type="bibr" target="#b55">[54]</ref>, while Alzubaidi et al. introduced a deep network archi-123 tecture that enhanced in classifying DFUs <ref type="bibr" target="#b59">[58]</ref>. Various CNN architectures, including ResNet and Efficient-Net, have been applied successfully in both binary and multiclass classification tasks, achieving high accuracy and precision for identifying infection and ischemia in chronic wounds. Hybrid models that combine deep features with hand-crafted features have also shown promising results. Traditional machine learning models like RF and DT have been effective in identifying high-risk patients and classifying wounds from clinical data. Additionally, novel approaches like transfer learning, explainable AI, and YOLO-based models have demonstrated high performance in wound detection and classification. These classification methods supports early diagnosis, optimal treatment planning, and identification of complications. For instance, correctly identifying diabetic foot ulcers or pressure ulcers helps guide targeted treatments such as offloading pressure or managing infection risks. The use of AI-based classification can assist clinicians in identifying high-risk patients earlier, allowing for proactive care interventions, thus reducing the risk of more severe complications like amputations or chronic nonhealing wounds.</p><p>Recent advancements in ML and DL have significantly enhanced wound assessment and healing prediction, with promising implications for clinical decision-making. For instance, the Reduced ResNet-18 model achieved an IoU rate above 0.5 in detecting granulation tissue in diabetic foot ulcers, showcasing the potential of lightweight networks in resource-constrained settings. Similarly, Liu et al. employed a DenseNet framework to assess wound attributes, attaining accuracy and F1 scores over 0.8, highlighting the effectiveness of sophisticated neural architectures <ref type="bibr" target="#b94">[93]</ref>. Clinically, models that predict wound healing potential can help clinicians make informed decisions about treatment duration and intensity, particularly for chronic wounds. For example, accurate detection of granulation tissue indicates the healing phase, which can guide decisions about whether to continue the current treatment regimen or explore more advanced therapies.</p><p>Incorporating patient empowerment, Chen et al. demonstrated that smartphone-based systems could accurately evaluate surgical wounds with over 90% accuracy, facilitating self-management in chronic wound care <ref type="bibr" target="#b96">[95]</ref>. Additionally, studies utilizing NB classifiers showed improved predictions for surgical site infections (SSIs) and hard-to-heal diabetic foot ulcers, with an impressive AUC of 0.864 achieved by <ref type="bibr">Wang et al. [98]</ref>. From a clinical perspective, smartphonebased systems enable patients to monitor their wounds in real-time, leading to improved self-management and earlier detection of complications. This can be especially beneficial for patients with chronic conditions like diabetes, where ongoing wound care is necessary to prevent complications such as infections or amputations. Empowering patients to track their healing progress fosters adherence to treatment plans and enhances overall outcomes.</p><p>Hybrid approaches that combine structured and unstructured data further enhance predictive accuracy, as shown by <ref type="bibr">Song et al. (2021)</ref>, where integrating clinical notes significantly improved outcomes for wound infection-related hospitalizations <ref type="bibr" target="#b101">[101]</ref>. Clinically, these hybrid models offer a comprehensive understanding of the patient's overall health status, allowing for more personalized care and better predictions of wound healing and complications. By integrating clinical data, such as comorbidities, treatment history, and wound characteristics, these models provide clinicians with more accurate risk assessments, guiding timely interventions and improving patient outcomes. Collectively, these studies underscore the transformative potential of ML and DL in wound care management, paving the way for more personalized treatment strategies. Continued research is needed to refine these models for broader clinical adoption, ultimately improving patient outcomes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relationship Between AI Models and Traditional Wound Assessment Tools</head><p>Advances in ML and DL have transformed chronic wound care, serving as both an alternative and a complement to traditional tools such as the PUSH, BWAT assessment scales, and digital planimetry. While these traditional methodologies, grounded in manual or semi-automated assessments, have been validated, they exhibit inherent limitations in terms of accuracy, efficiency, and subjectivity-limitations that AI seeks to address (Table <ref type="table" target="#tab_13">20</ref>).</p><p>Traditional tools rely heavily on clinical judgment, introducing variability into wound evaluations. Measurement devices like ruler or digital planimetry (e.g., Visitrak) improve precision by providing semi-automated wound area measurements. However, such tools still depend on user input for tracing wound boundaries, making them susceptible to inter-and intra-rater variability. AI-based tools like U-Net and AutoTrace, by contrast, enhance precision through full automation, segmenting wound areas and classifying tissue types consistently, even in chronic or irregular wound scenarios.</p><p>Furthermore, AI-based tools process data in real time. For example, Swift Medical has demonstrated a significant reduction in evaluation time, completing assessments in an average of 62 s per wound. This capability not only streamlines clinical workflows but also enables higher patient throughput without compromising accuracy.</p><p>Whereas traditional tools predominantly focus on static assessments, AI models integrate longitudinal data to predict clinical risks such as delayed healing or future infections. This predictive capability offers valuable insights that inform clinical decision-making and enable tailored treatment strate- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Studies Limitations</head><p>The evidence included in the review faces several limitations. One significant issue is the limited generalizability of many ML and DL models due to small or highly specific datasets. Most studies rely on curated wound datasets that may not reflect the diversity of real-world conditions, limiting their broader clinical applicability. Furthermore, many models are tested under controlled environments or specific conditions making it difficult to generalize their effectiveness across other wound types or patient populations.</p><p>Another limitation is the variability in performance metrics used across studies, such as accuracy, AUC, F1-score, and DSC, which complicates direct comparisons between different approaches. Moreover, some models face difficulties in accurately identifying certain types of tissues, suggesting that the current algorithms may not be equally effective at recognizing all features within a wound. This limitation can lead to incomplete or incorrect evaluations, particularly when dealing with more chronic wound types. To improve detection, models need to be specifically trained to recognize designated tissue types. If certain tissues are not included in the training set, the model will be unable to identify them during its analysis, leading to potential gaps in assessment.</p><p>The reliance on manual segmentation or annotations for model training and evaluation also introduces variability, especially in wound measurement and segmentation tasks, where human error can affect the ground truth. Additionally, many studies focus on retrospective data analysis rather than prospective trials, which may limit the assessment of model performance in real-time clinical settings.</p><p>Of the 93 studies included in this review, only 21 explicitly addressed wounds with irregular edges or multiple/noncontiguous lesions. This gap highlights a significant deficiency in the existing literature, especially considering that such characteristics are common in clinical practice, particularly among patients with venous ulcers or pressure injuries. These types of wounds present unique challenges for diagnosis and treatment, which limits the applicability of the AI tools reviewed to broader clinical scenarios. The absence of models and tools specifically designed to address these conditions underscores the need for future research focusing on such wounds to improve their management and the effectiveness of AI-based methods.</p><p>Lastly, while some models integrate XAI tools, the lack of interpretability in most ML/DL algorithms remains a concern, particularly in clinical environments where understanding the decision-making process is critical. This limits the trust and adoption of these technologies by healthcare professionals. More research is needed to refine these models, improve data diversity, and establish consistent evaluation standards to better validate their clinical utility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Future Research</head><p>Future research should focus on addressing the limitations of current AI and/or ML models, particularly their performance on diverse and chronic wound types, such as wounds with irregular edges or mixed tissue types. Developing larger and more diverse datasets, ensuring better data annotation quality, and creating models that generalize well to various clinical settings will be important next steps. A crucial aspect of this is the inclusion of real-world data in model training and validation. AI models trained on curated, controlled datasets may not perform adequately in the diverse, heterogeneous conditions encountered in everyday clinical practice. Incorporating wounds with varied geometries, sizes, and etiologies into training datasets is essential for developing robust, adaptable models that can handle the complexity of real-world scenarios.</p><p>Moreover, research should explore hybrid models that combine ML with traditional clinical data, including patient demographics, medical history, and environmental factors. Such approaches could enhance model performance by incorporating a broader context, improving decision-making in multifactorial wound care. Additionally, methods to improve the interpretability of AI algorithms will be vital for healthcare professionals, ensuring that AI tools are not seen as "black boxes" but as supportive, transparent systems that can explain their decision-making process.</p><p>There is also a need for prospective, real-world studies to validate the clinical efficacy of these AI tools and determine their long-term impact on patient outcomes. These studies should involve a variety of wound types and clinical contexts, reflecting the true diversity of cases seen in clinical practice. Furthermore, research into the cost-effectiveness of AI-driven wound care, as well as strategies for integrating these tools into existing healthcare infrastructures, will be critical for ensuring the sustainable implementation and widespread adoption of AI in wound management. This research will not only validate the clinical utility of AI tools but also ensure their accessibility and effectiveness across different healthcare settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>The studies reviewed illustrate the transformative potential of ML and DL approaches in wound assessment, classification, and measurement. Techniques such as SVM, CNN, and advanced hybrid models have achieved impressive accuracy and efficiency in distinguishing between different tissue types, quantifying wound characteristics, and predicting healing outcomes. For example, models like the Efficient-NetB0 and DeepMedic have shown high performance in segmenting and classifying wound tissues, while smartphone applications enable patients to participate actively in their care. However, challenges remain, particularly in accurately identifying specific tissue types like epithelial cells and managing chronic wound boundaries. Continued advancements in algorithm development, as well as the integration of structured and unstructured data, are essential for further enhancing the precision of wound care technologies. Ultimately, these innovations promise to improve clinical workflows, support personalized treatment strategies, and lead to better patient outcomes in wound management.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1</head><label>1</label><figDesc>Fig.1PRISMA Flow Diagram summarizing the selection process<ref type="bibr" target="#b19">[19]</ref> </figDesc><graphic coords="4,84.13,56.90,426.04,370.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 Fig. 4</head><label>34</label><figDesc>Fig. 3 Task distribution between selected reports</figDesc><graphic coords="5,183.25,488.30,360.76,224.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Key evaluation metrics used in chronic wound diagnosis with AI models</figDesc><table><row><cell>Metric</cell><cell cols="2">Formula</cell><cell></cell><cell>Definition</cell></row><row><cell>Accuracy</cell><cell>Acc =</cell><cell cols="2">T P+T N T P+T N+F P+F N</cell><cell>The proportion of correct predictions made by the</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>model compared to the total number of instances</cell></row><row><cell>Recall, Sensitivity or True</cell><cell cols="3">SE = T P T P+F N</cell><cell>The proportion of true positives correctly identified</cell></row><row><cell>Positive Rate (TPR)</cell><cell></cell><cell></cell><cell></cell><cell>by the model, crucial for ensuring that no important</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>chronic wound cases are missed</cell></row><row><cell>Specificity</cell><cell cols="3">S P = T N T N+F P</cell><cell>The proportion of actual negatives correctly identified,</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>helping to measure how well the model avoids false</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>positives</cell></row><row><cell>Precision or Positive Predic-</cell><cell cols="3">P = T P T P+F P</cell><cell>The proportion of true positive results in all predicted</cell></row><row><cell>tive Value (PPV)</cell><cell></cell><cell></cell><cell></cell><cell>positives. Important when the cost of false positives</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>is high</cell></row><row><cell>F1-Score</cell><cell cols="2">P = 2  *</cell><cell>1 precision + 1 1 recall</cell><cell>The harmonic mean of precision and recall, provid-ing a balance between the two. Useful in imbalanced</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>datasets to ensure both false positives and false nega-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>tives are minimized</cell></row><row><cell>False Positive Rate (FPR)</cell><cell cols="3">P = F P F P+T N</cell><cell>The rate of false positives in relation to actual negative</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>cases, important for ensuring that the AI model does</cell></row><row><cell>Matthews Correlation Coef-</cell><cell cols="3">MCC = (TP * TN -FP * FN) /</cell><cell>√ ((TP</cell><cell>not incorrectly classify healthy tissue as problematic</cell></row><row><cell>ficient (MCC)</cell><cell cols="4">+ FP) * (TP + FN) * (TN + FP) *</cell></row><row><cell></cell><cell cols="3">(TN + FN))</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>Summary of articles with tissue classification implemented</figDesc><table><row><cell>Outcomes</cell><cell>Accuracy: Granulation</cell><cell>86.94%, Slough 90.47%,</cell><cell>Necrotic 75.53%</cell><cell>Mean IoU = 0.8644 for</cell><cell>wound segmentation,</cell><cell>0.7192 for tissue segmen-</cell><cell>tation. High F1-scores for</cell><cell>slough (0.731) and eschar</cell><cell>(0.802)</cell><cell>Accuracy 92.01%, Weighted</cell><cell>DSC 91.38%, Precision</cell><cell>for granulation 97.31%,</cell><cell>necrotic tissue 96.59%,</cell><cell>slough 77.90%</cell><cell>Accuracy: NN = 81.87%, RF</cell><cell>= 87.37%, SVM = 88.08%</cell><cell></cell><cell>AUC = 95%, DSC = 92%,</cell><cell>PAD = 10%</cell></row><row><cell>Samples</cell><cell>74 images from Medetec</cell><cell>medical image database</cell><cell></cell><cell>58 images from Swift Medi-</cell><cell>cal's Wound Database</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>22 images acquired from</cell><cell>the Igurko Hospital, Bilbao-</cell><cell>Spain</cell><cell></cell><cell></cell><cell>255 samples taken by clin-</cell><cell>icians from home-care</cell><cell>patients</cell><cell>193 images from health-</cell><cell>care services company in the</cell><cell>Basque Country (Spain)</cell></row><row><cell>Wound type</cell><cell>Burn, DFU, Malignant</cell><cell>ulcer, Pyoderma gangreno-</cell><cell>sum, VU, PU</cell><cell>PU, AU, VU</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>PU</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>PU</cell><cell></cell><cell></cell><cell>PU</cell></row><row><cell>Validation methods</cell><cell>Kappa Statistic for tissue</cell><cell>pixel classification, Accu-</cell><cell>racy computation</cell><cell>IoU, F1-Score, Precision,</cell><cell>Recall</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Accuracy, Dice Similarity</cell><cell>Coefficient, Sensitivity,</cell><cell>Specificity</cell><cell></cell><cell></cell><cell>Accuracy, Cohen's kappa</cell><cell>coefficient</cell><cell></cell><cell>AUC, DSC, PAD</cell></row><row><cell>Technology</cell><cell>S V M , B N ( R G B t o H S I ,</cell><cell>fuzzy divergence-based</cell><cell>thresholding)</cell><cell>Encoder-decoder CNN with</cell><cell>EfficientNetB0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>CNN (9 layers, 3 convolu-</cell><cell>tion)</cell><cell></cell><cell></cell><cell></cell><cell>K-means for segmentation,</cell><cell>NN, RF, SVM for classifica-</cell><cell>tion</cell><cell>DeepMedic multi-pathway</cell><cell>3D CNN, Gaussian kernel</cell><cell>smoothing</cell></row><row><cell>Article</cell><cell>Mukherjee et al. [28]</cell><cell></cell><cell></cell><cell>Ramachandram et al. [29]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Zahia et al. [30]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Veredas et al. [31]</cell><cell></cell><cell></cell><cell>García-Zapirain et al. [32]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell></cell><cell>Outcomes</cell><cell>AI tool was significantly</cell><cell>faster with an average time</cell><cell>of 62 s per assessment</cell><cell>Intra-rater reliability ranged</cell><cell>0.933-0.994; inter-rater</cell><cell>reliability for length = 0.947</cell><cell>Higher error in desktop</cell><cell>method than mobile device</cell><cell>implementation</cell><cell>Dice = 90.9%, IoU = 83.9%,</cell><cell>accuracy = 99.3%, speci-</cell><cell>ficity = 99.6%; some errors</cell><cell>on irregular edges</cell><cell>DICE increased from</cell><cell>36.53% to 86.3%, IoU</cell><cell>from 29.48% to 77.09%,</cell><cell>overall DICE = 93.04%</cell><cell>High reliability; uses cali-</cell><cell>brator to detect pixels and</cell><cell>compute distances</cell></row><row><cell></cell><cell>Samples</cell><cell>91 patients with 115 wounds</cell><cell></cell><cell></cell><cell>75 wound episodes from 28</cell><cell>patients (547 images)</cell><cell></cell><cell>10 images from Science</cell><cell>Photo Library, iStockPhoto</cell><cell>and professionals</cell><cell>565 samples captured with</cell><cell>AreaMe software</cell><cell></cell><cell></cell><cell>569 CW, 270 DFU images</cell><cell>from 7 patients</cell><cell></cell><cell></cell><cell>36 patients, 107 finger</cell><cell>lesions</cell></row><row><cell></cell><cell>Wound type</cell><cell>VU, DFU, SW</cell><cell></cell><cell></cell><cell>DFU</cell><cell></cell><cell></cell><cell>CW</cell><cell></cell><cell></cell><cell>DFU</cell><cell></cell><cell></cell><cell></cell><cell>DFU</cell><cell></cell><cell></cell><cell></cell><cell>Digital ulcers (SSc)</cell><cell></cell></row><row><cell>Summary of articles with wound measurement implemented</cell><cell>Article Technology Validation methods</cell><cell>Mohammed et al. [9] AI-based wound assessment Intraclass correlation coeffi-</cell><cell>application (Swift Medical) cient (ICC) test</cell><cell></cell><cell>Chan et al. [33] CARES4WOUNDS (C4W) Intra-and inter-rater reliabil-</cell><cell>system ity via intraclass correlation</cell><cell>statistics</cell><cell>Ferreira et al. [35] Computer vision Mean absolute error (MAE)</cell><cell>(Grayscale, Canny detec-</cell><cell>tion, OpenCV)</cell><cell>Foltynski et al. [36] U-Net CNN for segmenta-Dice similarity, IoU, accu-</cell><cell>tion racy, specificity</cell><cell></cell><cell></cell><cell>Niri et al. [37] DL-based segmentation Dice similarity, IoU, RMSE,</cell><cell>with 3D model reconstruc-MAE</cell><cell>tion</cell><cell></cell><cell>Simpson et al. [34] Digital planimetry (ellipse, Intraclass correlation coeffi-</cell><cell>free hand ROI) cient, mean, intra-and inter-</cell><cell>rater reliability</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>123</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4</head><label>4</label><figDesc>Summary of articles with wound segmentation and DL methods implemented</figDesc><table><row><cell>Outcomes</cell><cell>The highest values obtained</cell><cell>with UNet VGG16 (AUC</cell><cell>0.998). UNet faster than</cell><cell>UNet-VGG16</cell><cell>U-Net and FCN models</cell><cell>MCC=[0.84-0.78] and</cell><cell>MCC=[0.770-0.768],</cell><cell>respectively</cell><cell>ResNet101_Kitti the high-</cell><cell>est precision (mAP of 87).</cell><cell>ResNet101_fgvc the fastest</cell><cell>(speed of 395ms)</cell><cell>Recall 89.97%, Precision</cell><cell>91.01%, accuracy (DSC</cell><cell>90.47%), surpassing U-Net,</cell><cell>Mask-RCNN and VGG16</cell></row><row><cell>Samples</cell><cell>440 images (400 PU, 20</cell><cell>DFU, 20 VLU) from Kyorin</cell><cell>University Hospital patients</cell><cell></cell><cell>1096 images from 76</cell><cell>patients</cell><cell></cell><cell></cell><cell>727 images from Taichung</cell><cell>Rongmin General Hospital</cell><cell></cell><cell></cell><cell>1109 images from 889</cell><cell>patients</cell><cell></cell><cell></cell></row><row><cell>Wound type</cell><cell>PU, DFU, VLU</cell><cell></cell><cell></cell><cell></cell><cell>DFU, Digital Ulcers</cell><cell></cell><cell></cell><cell></cell><cell>DFU</cell><cell></cell><cell></cell><cell></cell><cell>DFU</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Validation methods</cell><cell>AUC, F1-score, Sensitivity,</cell><cell>Specificity, Accuracy</cell><cell></cell><cell></cell><cell>MCC, DSC, IoU</cell><cell></cell><cell></cell><cell></cell><cell>Accuracy</cell><cell></cell><cell></cell><cell></cell><cell>Precision, Recall, Dice</cell><cell>Coefficient</cell><cell></cell><cell></cell></row><row><cell>Technology</cell><cell>Comparison of CNN archi-</cell><cell>tectures for segmentation</cell><cell>(SegNet, LinkNet, U-Net,</cell><cell>U-Net VGG16)</cell><cell>DL model compared U-Net,</cell><cell>ConvNet, DeepLab, FCN for</cell><cell>wound detection and seg-</cell><cell>mentation</cell><cell>ResNet-based image recog-</cell><cell>nition for diabetic foot</cell><cell>wounds</cell><cell></cell><cell>MobileNetV2-based model</cell><cell>compared to FCN-VGG16,</cell><cell>SegNet, Mask-RCNN, U-</cell><cell>Net</cell></row><row><cell>Article</cell><cell>Ohura et al. [38]</cell><cell></cell><cell></cell><cell></cell><cell>Scebba et al. [39]</cell><cell></cell><cell></cell><cell></cell><cell>Wang et al. [41]</cell><cell></cell><cell></cell><cell></cell><cell>Huang et al. [40]</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5</head><label>5</label><figDesc>Summary of articles with wound segmentation and novel methods implemented</figDesc><table><row><cell>Outcomes</cell><cell>mean IoU 86.4680%, max.</cell><cell>IoU 86.7427%, Precision =</cell><cell>95.0262%</cell><cell>The Db color channel 91.5%</cell><cell>accuracy, 86.7% DSC,</cell><cell>79.0% JI, 87.3% sensitivity</cell><cell>and 95.7% specificity</cell><cell>Livewire best performance:</cell><cell>97.08%, 99.68% 96.67%,</cell><cell>96.22, 98.15, and 32.26,</cell><cell>mean values, respectively,</cell><cell>for accuracy, sensitivity,</cell><cell>specificity, JI, DS, and HD</cell><cell>specificity:&gt;95% and</cell><cell>sensitivity:&gt;77%</cell><cell></cell><cell>accuracy 96%, sensitivity</cell><cell>94%, specificity 97%, inter-</cell><cell>section over union 89% and</cell><cell>precision 94%</cell></row><row><cell>Samples</cell><cell>950 images from Medetec</cell><cell>database</cell><cell></cell><cell>70 images from 64 patients</cell><cell></cell><cell></cell><cell></cell><cell>26 images from 15 subjects</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>100 images from 15 patients</cell><cell></cell><cell></cell><cell>105 images from MEDE-</cell><cell>TEC</cell><cell></cell></row><row><cell>Wound type</cell><cell>CW</cell><cell></cell><cell></cell><cell>CW</cell><cell></cell><cell></cell><cell></cell><cell>DFU, Burns, Scar</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>DFU</cell><cell></cell><cell></cell><cell>PU</cell><cell></cell><cell></cell></row><row><cell>Validation methods</cell><cell>IoU, Precision</cell><cell></cell><cell></cell><cell>Accuracy, Sensitivity, Speci-</cell><cell>ficity, Dice Coefficient, JI</cell><cell></cell><cell></cell><cell>Precision, Sensitivity, Speci-</cell><cell>ficity, JI, DS, HD</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Specificity, Sensitivity</cell><cell></cell><cell></cell><cell>Accuracy, Precision, Speci-</cell><cell>ficity, Sensitivity, IoU</cell><cell></cell></row><row><cell>Technology</cell><cell>MobileNet with location-</cell><cell>enhanced convolution ker-</cell><cell>nels for segmentation</cell><cell>Spectral clustering with</cell><cell>fuzzy similarity measures</cell><cell>for segmentation</cell><cell></cell><cell>Comparison of three edge-</cell><cell>based algorithms for wound</cell><cell>segmentation</cell><cell></cell><cell></cell><cell></cell><cell>Wound boundary detection</cell><cell>using associative hierarchi-</cell><cell>cal random field (AHRF)</cell><cell>Superpixel strategy using</cell><cell>SVM and GrabCut</cell><cell></cell></row><row><cell>Article</cell><cell>Dhane et al. [43]</cell><cell></cell><cell></cell><cell>Li et al. [42]</cell><cell></cell><cell></cell><cell></cell><cell>Gholami et al. [44]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Wang et al. [45]</cell><cell></cell><cell></cell><cell>Silva et al. [46]</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 7</head><label>7</label><figDesc>Summary of articles with wound segmentation and ML methods implemented</figDesc><table><row><cell>Outcomes</cell><cell>Most accurate in the Db</cell><cell>channel (accuracy fuzzy c-</cell><cell>means 84.20% and k-means</cell><cell>82.39%. Accuracies 62.29%</cell><cell>and 66.20% in other chan-</cell><cell>nels</cell><cell>46% of cases improve seg-</cell><cell>mentation, 16% unchanged</cell><cell>quality and 38% quality</cell><cell>degraded</cell><cell>Accuracy 86.73%, with</cell><cell>91.80% PPV and 89.54%</cell><cell>sensitivity; k-means the</cell><cell>lowest accuracy; high-</cell><cell>est sensitivity with fuzzy</cell><cell>c-means (87.98% and</cell><cell>88.77%)</cell><cell>Average accuracy rate</cell><cell>improved about 3% than the</cell><cell>traditional methods</cell><cell>AUC 94,26% (SD.0563);</cell><cell>accuracy: 87,77%</cell><cell>(SD.0799); F-score 73,89%</cell><cell>(SD.1550); Cohen's kappa</cell><cell>65,85% (SD.1787)</cell></row><row><cell>Samples</cell><cell>77 images from Medetec</cell><cell>database</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>50 images from Medetec</cell><cell>database</cell><cell></cell><cell></cell><cell>105 images from 64 partici-</cell><cell>pants</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>300 images from Medetec</cell><cell>database</cell><cell></cell><cell>435 images from 69 patients</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Wound type</cell><cell>PU, DFU, VU, MU, PG</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>PU, VU, AU, Burns, Scalds</cell><cell></cell><cell></cell><cell></cell><cell>PU, LU, DFU</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>CW</cell><cell></cell><cell></cell><cell>PU</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Validation methods</cell><cell>Accuracy, PPV, Sensitivity</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Visual validation</cell><cell></cell><cell></cell><cell></cell><cell>Accuracy, Sensitivity, PPV</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Accuracy</cell><cell></cell><cell></cell><cell>AUC, F-Score, Kappa, Sen-</cell><cell>sitivity, Specificity, Accu-</cell><cell>racy</cell><cell></cell><cell></cell></row><row><cell>Technology</cell><cell>k-means and fuzzy c-means</cell><cell>clustering using YDbDr</cell><cell>color space</cell><cell></cell><cell></cell><cell></cell><cell>PSO for binary image seg-</cell><cell>mentation compared with</cell><cell>Otsu method</cell><cell></cell><cell>Spectral clustering for</cell><cell>wound bed identification</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>CNN model fwith color cor-</cell><cell>rection</cell><cell></cell><cell>K-means based statistical</cell><cell>color models</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Article</cell><cell>Yadav et al. [49]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Atisattapong et al. [50]</cell><cell></cell><cell></cell><cell></cell><cell>Dhane et al. [51]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Lu et al. [52]</cell><cell></cell><cell></cell><cell>Veredas et al. [53]</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>123</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 8</head><label>8</label><figDesc>Summary of articles with real-time CW detection on mobile devices</figDesc><table><row><cell>Outcomes</cell><cell>Averaged precision of</cell><cell>91.8%, InceptionV2 the</cell><cell>best performance. SSD-</cell><cell>Mobilenet faster model but</cell><cell>worst in accuracy</cell><cell>AHRF outperforms U-Net</cell><cell>on small datasets (&lt; 300</cell><cell>images) but is slower and</cell><cell>less accurate than FCN</cell><cell>and DeepLabV3, while</cell><cell>CNNs are superior on larger</cell><cell>datasets</cell><cell>mAP 0.97; Superior to SSD</cell><cell>with a 7.5% higher mAP on</cell><cell>AZH dataset</cell></row><row><cell>Samples</cell><cell>1775 images from the Lan-</cell><cell>cashire Teaching Hospitals</cell><cell></cell><cell></cell><cell></cell><cell>1442 images from local cap-</cell><cell>ture, scraping internet and</cell><cell>from University of Mas-</cell><cell>sachusetts Medical Center</cell><cell></cell><cell></cell><cell></cell><cell>1800 images (from AZH and</cell><cell>MEDETEC)</cell><cell></cell></row><row><cell>Wound type</cell><cell>DFU</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>CW</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>DFU, PU, VU</cell><cell></cell><cell></cell></row><row><cell>Validation methods</cell><cell>Speed, Model Size, mAP,</cell><cell>Overlap Percentage</cell><cell></cell><cell></cell><cell></cell><cell>Dice Score, Inference Time</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Precision, Recall, F1-score,</cell><cell>IoU, mAP</cell><cell></cell></row><row><cell>Technology</cell><cell>Deep learning models</cell><cell>(MobileNet, Inception-V2)</cell><cell></cell><cell></cell><cell></cell><cell>AHRF vs. CNNs (FCN, U-</cell><cell>Net, DeepLabV3)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>2D wound images and</cell><cell>YOLOv3 vs. SSD</cell><cell></cell></row><row><cell>Article</cell><cell>Goyal et al. [54]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Wagh et al. [55]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Anisuzzaman et al. [56]</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 9</head><label>9</label><figDesc>Summary of articles on wound classification using variants of CNN model</figDesc><table><row><cell>Outcomes</cell><cell>93.4% sensitivity, 0.962</cell><cell>AUC</cell><cell>DFU-QUTNet with SVM</cell><cell>95.4% precision and 94.5%</cell><cell>F1-score</cell><cell>accuracy ischemia 90%,</cell><cell>infection 73%</cell><cell></cell><cell>CKB-DeiT-B-D achieved</cell><cell>F1-score of 78.20 and AUC</cell><cell>of 84.78</cell><cell>Highest accuracy of 86.67%</cell><cell>on Medetec dataset using</cell><cell>VGG19 + MLP</cell><cell>ResNet50 accuracy</cell><cell>ischemia 99.49%, infec-</cell><cell>tion 84.76%</cell><cell>DNN 97.43% accuracy with</cell><cell>healthy and infected</cell><cell></cell><cell>91.98% accuracy for infec-</cell><cell>tion classification</cell><cell>Mask-RCNN Acc. 92.6%</cell><cell>classification and 93.0%</cell><cell>segmentation. F1-scores</cell><cell>[0.842-0.947]</cell><cell>Res4Net accuracy ischemia</cell><cell>97.8%, Res7Net AUC infec-</cell><cell>tion 0.889</cell></row><row><cell>Samples</cell><cell>292 images from Lancashire</cell><cell>Teaching Hospitals</cell><cell>754 images from the</cell><cell>Nasiriyah Hospital's dia-</cell><cell>betic center</cell><cell>1249 ischemia, 628 infection</cell><cell>cases from the Lancashire</cell><cell>Teaching Hospitals</cell><cell>628 infection, 1249 ischemia</cell><cell>cases from the Lancashire</cell><cell>Teaching Hospitals</cell><cell>730 images (AZH), 358</cell><cell>(Medetec)</cell><cell></cell><cell>1459 images from DFU2020</cell><cell>database</cell><cell></cell><cell>756 images from the diabetic</cell><cell>center of Nasiriyah's Hospi-</cell><cell>tal</cell><cell>5890 images from the Lan-</cell><cell>cashire Teaching Hospitals</cell><cell>969 images provided by</cell><cell>eKare Inc. (Fairfax, VA)</cell><cell></cell><cell></cell><cell>210 ischemia, 628 infection</cell><cell>cases from Department of</cell><cell>Computing and Mathemat-</cell><cell>ics</cell></row><row><cell>Wound type</cell><cell>DFU</cell><cell></cell><cell>DFU</cell><cell></cell><cell></cell><cell>DFU</cell><cell></cell><cell></cell><cell>DFU</cell><cell></cell><cell></cell><cell>DFU, PU, VU, SW</cell><cell></cell><cell></cell><cell>DFU</cell><cell></cell><cell></cell><cell>DFU</cell><cell></cell><cell></cell><cell>DFU</cell><cell></cell><cell>PU</cell><cell></cell><cell></cell><cell></cell><cell>DFU</cell></row><row><cell>Validation methods</cell><cell>Sensitivity, specificity, F-</cell><cell>measure, AUC</cell><cell>Precision, recall, F1-score</cell><cell></cell><cell></cell><cell>Accuracy, sensitivity, MCC,</cell><cell>AUC</cell><cell></cell><cell>Accuracy, sensitivity, preci-</cell><cell>sion, F1-score, AUC</cell><cell></cell><cell>Accuracy, precision, recall,</cell><cell>F1-score</cell><cell></cell><cell>Sensitivity, specificity, accu-</cell><cell>racy, MCC</cell><cell></cell><cell>Recall, specificity, preci-</cell><cell>sion, accuracy</cell><cell></cell><cell>Accuracy, MCC</cell><cell></cell><cell>Precision, Recall, Accuracy,</cell><cell>F1 Score</cell><cell></cell><cell></cell><cell>Accuracy, F1-Score, AUC,</cell><cell>MCC</cell></row><row><cell>Technology</cell><cell>DFUNet, CNN-based model</cell><cell></cell><cell>DFU-QUTNet CNN, SVM</cell><cell></cell><cell></cell><cell>Faster R-CNN, deep learn-</cell><cell>ing</cell><cell></cell><cell>Class Knowledge Bank</cell><cell>(CKB), ResNet, Efficient-</cell><cell>Net, and DeiT</cell><cell>Multi-modal classifier</cell><cell>(VGG16, ResNet50)</cell><cell></cell><cell>CNN architectures</cell><cell>(AlexNet, VGG16,</cell><cell>ResNet50, etc.)</cell><cell>CNN-GLCMNet combining</cell><cell>CNN and GLCM</cell><cell></cell><cell>DFINET, CNN-based model</cell><cell></cell><cell>Mask-RCNN for segmenta-</cell><cell>tion and classification of PU</cell><cell>stages 1-4</cell><cell></cell><cell>ResNet, CNN (Res4Net,</cell><cell>Res7Net)</cell></row><row><cell>Article</cell><cell>[57]</cell><cell></cell><cell>[58]</cell><cell></cell><cell></cell><cell>[59]</cell><cell></cell><cell></cell><cell>[60]</cell><cell></cell><cell></cell><cell>[61]</cell><cell></cell><cell></cell><cell>[62]</cell><cell></cell><cell></cell><cell>[63]</cell><cell></cell><cell></cell><cell>[64]</cell><cell></cell><cell>[65]</cell><cell></cell><cell></cell><cell></cell><cell>[66]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 11</head><label>11</label><figDesc>Summary of articles on wound classification using ML models</figDesc><table><row><cell>Outcomes</cell><cell>RF achieved best perfor-</cell><cell>mance with AUC of 0.864</cell><cell>RF achieved 95% AUC for</cell><cell>PU detection</cell><cell>80.4% accuracy, identifying</cell><cell>length of stay and comorbid-</cell><cell>ity as key factors</cell><cell>97% accuracy for high-risk</cell><cell>DFU classification</cell></row><row><cell>Samples</cell><cell>11838 inpatient records</cell><cell></cell><cell>3589 cases (MIMIC-III</cell><cell>dataset)</cell><cell>15856 cases from the 2014</cell><cell>NIS provided by HIRA</cell><cell>(HIRA-NIS-2014-0071)</cell><cell>153 patients</cell><cell></cell></row><row><cell>Wound type</cell><cell>PU</cell><cell></cell><cell>PU</cell><cell></cell><cell>PU</cell><cell></cell><cell></cell><cell>DFU</cell><cell></cell></row><row><cell>Validation methods</cell><cell>Precision, recall, specificity,</cell><cell>F1-score, AUC</cell><cell>AUC, ROC, F1 score</cell><cell></cell><cell>Accuracy, sensitivity, speci-</cell><cell>ficity</cell><cell></cell><cell>Silhouette, accuracy</cell><cell></cell></row><row><cell>Technology</cell><cell>DT, LR, RF</cell><cell></cell><cell>LR, RF, NN</cell><cell></cell><cell>Decision tree analysis</cell><cell></cell><cell></cell><cell>K-means clustering</cell><cell></cell></row><row><cell>Article</cell><cell>[71]</cell><cell></cell><cell>[72]</cell><cell></cell><cell>[73]</cell><cell></cell><cell></cell><cell>[74]</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 14</head><label>14</label><figDesc>Summary of articles on wound classification with comparative studies of ML models</figDesc><table><row><cell>Outcomes</cell><cell>ResNet achieved 83.3%</cell><cell>AUC for infection detec-</cell><cell>tion, outperforming other</cell><cell>classifiers</cell><cell>MLP achieved highest accu-</cell><cell>racy (83.05%) for binary</cell><cell>classification</cell><cell>CNN sensitivity (97%) out-</cell><cell>performed dermatologists</cell><cell></cell><cell>RF model achieved the high-</cell><cell>est accuracy and AUC (both</cell><cell>&gt; 0.95)</cell><cell>RF achieved 96% accuracy</cell><cell></cell><cell>98.79% accuracy for oral</cell><cell>ulcer classification</cell><cell></cell><cell></cell><cell>ELM achieved 96.15% accu-</cell><cell>racy, outperforming KNN,</cell><cell>SVM, and ANN</cell><cell>87.6% recall for leg wounds</cell></row><row><cell>Samples</cell><cell>480 wound photographs</cell><cell>from 100 surgical patients</cell><cell></cell><cell></cell><cell>59 images from the Medetec</cell><cell>Medical Image Database</cell><cell></cell><cell>491 images from patients</cell><cell>treated in two large derma-</cell><cell>tology centers</cell><cell>5814 patients</cell><cell></cell><cell></cell><cell>4652 patients</cell><cell></cell><cell>360 images from dataset</cell><cell>labeled by dental specialists</cell><cell>from Fujian Stomatological</cell><cell>Hospital</cell><cell>22 attributes and 133</cell><cell>instances from the</cell><cell>"Figshare" data repository</cell><cell>1337 images from 34 cardio-</cell><cell>thoracic surgery patients of</cell><cell>Hospital de Santa Marta dur-</cell><cell>ing a 30-day follow-up</cell></row><row><cell>Wound type</cell><cell>SW</cell><cell></cell><cell></cell><cell></cell><cell>PU, VU, AU</cell><cell></cell><cell></cell><cell>Pyoderma gangrenosum, leg</cell><cell>ulcers</cell><cell></cell><cell>PU</cell><cell></cell><cell></cell><cell>PU</cell><cell></cell><cell>Oral ulcers</cell><cell></cell><cell></cell><cell></cell><cell>DFU</cell><cell>SW</cell></row><row><cell>Validation methods</cell><cell>Accuracy, recall, precision,</cell><cell>F1-score, AUC</cell><cell></cell><cell></cell><cell>Accuracy</cell><cell></cell><cell></cell><cell>Sensitivity, specificity, accu-</cell><cell>racy</cell><cell></cell><cell>Accuracy, AUC</cell><cell></cell><cell></cell><cell>AUC, ROC</cell><cell></cell><cell>Sensitivity, specificity, accu-</cell><cell>racy</cell><cell></cell><cell></cell><cell>Accuracy, TS/CSI, FDR</cell><cell>Accuracy, precision, recall,</cell><cell>F1, AUC</cell></row><row><cell>Technology</cell><cell>Expert system, ResNet-</cell><cell>based model</cell><cell></cell><cell></cell><cell>MLP, SVM, RF, NB</cell><cell></cell><cell></cell><cell>InceptionV3, ResNet50,</cell><cell>VGG16</cell><cell></cell><cell>SVM, DT, RF, ANN</cell><cell></cell><cell></cell><cell>LR, KNN, SVM, RF, MLP,</cell><cell>BN</cell><cell>Variant of Residual Network</cell><cell></cell><cell></cell><cell></cell><cell>ELM, KNN, SVM, ANN</cell><cell>Deep learning segmentation,</cell><cell>machine learning models</cell></row><row><cell>Article</cell><cell>[83]</cell><cell></cell><cell></cell><cell></cell><cell>[84]</cell><cell></cell><cell></cell><cell>[85]</cell><cell></cell><cell></cell><cell>[86]</cell><cell></cell><cell></cell><cell>[87]</cell><cell></cell><cell>[88]</cell><cell></cell><cell></cell><cell></cell><cell>[89]</cell><cell>[90]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 17</head><label>17</label><figDesc>Summary of articles on various methods with CNN approaches implemented</figDesc><table><row><cell>Outcomes</cell><cell>QTDU accurately spots</cell><cell>wounded tissues (AUC =</cell><cell>0.986, sensitivity = 0.97, and</cell><cell>specificity = 0.974) with an</cell><cell>F1-score improvement up to</cell><cell>8.2% using a ResNet-based</cell><cell>model</cell><cell>Best segmentation results</cell><cell>with Mask-RCNN (mean</cell><cell>Dice score: 0.83, sensitivity:</cell><cell>0.85, precision: 0.87), MAE</cell><cell>for wound depth: 0.74 cm,</cell><cell>volume: 4.69 cm3</cell><cell>DeeplabV3 performed best</cell><cell>with precision of 0.9915,</cell><cell>recall of 0.9915, and accu-</cell><cell>racy of 0.9957 for tissue</cell><cell>classification</cell><cell></cell><cell>Dice score greater than 90%,</cell><cell>able to estimate wound area</cell><cell>with a relative error of 12.1%</cell><cell></cell><cell>93.75% overall accuracy,</cell><cell>Random Forest provided</cell><cell>85.67% accuracy</cell></row><row><cell>Samples</cell><cell>217 photos from</cell><cell>ULCER_SET database</cell><cell>with images from Neurovas-</cell><cell>cular Ulcers Outpatient</cell><cell>Clinic of HCFMRP/USP</cell><cell></cell><cell></cell><cell>210 photos (110 from hos-</cell><cell>pitals, 100 from Medetec</cell><cell>MIOD)</cell><cell></cell><cell></cell><cell></cell><cell>2836 images labeled for tis-</cell><cell>sue classification, 2893 for</cell><cell>re-ep segmentation</cell><cell></cell><cell></cell><cell></cell><cell>446 images from ULCER</cell><cell>and ULCER-2 database</cell><cell></cell><cell></cell><cell>153 images (60 granulation,</cell><cell>20 slough, 53 necrosis)</cell></row><row><cell>Wound type</cell><cell>AU and VU</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>PU</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>PU</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>VU and AU</cell><cell></cell><cell></cell><cell></cell><cell>CW</cell></row><row><cell>Validation methods</cell><cell>Cohen-Kappa, Coefficient,</cell><cell>F1-Score, Sensitivity, Speci-</cell><cell>ficity, and AUC</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Dice Similarity Coefficient</cell><cell>(DSC), Sensitivity, Pre-</cell><cell>cision for segmentation,</cell><cell>MAE, RMSE for measure-</cell><cell>ment evaluation</cell><cell></cell><cell>F1-score, IoU, Precision,</cell><cell>Recall, Accuracy</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Dice Score, Jaccard Coeffi-</cell><cell>cient, Precision, Recall</cell><cell></cell><cell></cell><cell>Accuracy compared with</cell><cell>expert clinicians' manual</cell><cell>segmentation</cell></row><row><cell>Technology</cell><cell>InceptionV3 and ResNet</cell><cell>models with superpixel-</cell><cell>driven segmentation for</cell><cell>ulcers' quality assessment</cell><cell></cell><cell></cell><cell></cell><cell>CNN for wound segmenta-</cell><cell>tion and 3D mesh for depth,</cell><cell>volume, area, and axes com-</cell><cell>putation (Mask R-CNN with</cell><cell>ResNet50 and ResNet101)</cell><cell></cell><cell>Region-based labeling</cell><cell>method with DL models (U-</cell><cell>Net, DeeplabV3, PsPNet,</cell><cell>FPN, Mask R-CNN with</cell><cell>ResNet-101) for segmenta-</cell><cell>tion</cell><cell>Encoder/decoder DNN to</cell><cell>segment wound area, detects</cell><cell>ruler/tape for pixel density</cell><cell>estimation</cell><cell>Fuzzy c-means clustering</cell><cell>and machine learning for</cell><cell>wound tissue classification</cell></row><row><cell>Article</cell><cell>[103]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>[104]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>[105]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>[106]</cell><cell></cell><cell></cell><cell></cell><cell>[107]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 19</head><label>19</label><figDesc>Summary of articles on various methods with ML techniques implemented and mobile technologies used</figDesc><table><row><cell>Outcomes</cell><cell>Best algorithm mean IoU of</cell><cell>0.6964 wound area, 0.3957</cell><cell>epithelialization, 0.6421</cell><cell>granulation, and 0.1552</cell><cell>necrotic tissue</cell><cell></cell><cell>84.6% accuracy for wound</cell><cell>depth and granulation tissue</cell><cell>amount classification</cell><cell></cell><cell>89.04% accuracy, with</cell><cell>76.44% TPR. Symptom</cell><cell>detection 87.31% accu-</cell><cell>racy. Symptom assessment</cell><cell>83.58%</cell><cell></cell><cell>Best performance for linear</cell><cell>SVM (accuracy: 76%, preci-</cell><cell>sion: 75%, JI: 68%)</cell><cell></cell><cell></cell><cell>High accuracy in Visual</cell><cell>Computing methods.</cell><cell>ResNet50 for classifica-</cell><cell>tion 0.85 accuracy, area</cell><cell>measurement Median Rela-</cell><cell>tive Error of 2.907</cell><cell>97% accuracy compared to</cell><cell>physicians' WBP classifica-</cell><cell>tions, and tissue segmenta-</cell><cell>tion using devices like Vis-</cell><cell>itrak and MOWA</cell></row><row><cell>Samples</cell><cell>31 images from 20 patients</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1639 images publicly avail-</cell><cell>able on the Internet and from</cell><cell>University of Massachusetts</cell><cell>Medical School (UMMS)</cell><cell>293 images provided by</cell><cell>Department of Surgery and</cell><cell>Department of In-ternal</cell><cell>Medicine of National Tai-</cell><cell>wan University Hospital</cell><cell>(NTUH)</cell><cell>31 photos from a survey in a</cell><cell>long-term medical facility in</cell><cell>Japan</cell><cell></cell><cell></cell><cell>726 images from patients</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>150 patients</cell></row><row><cell>Wound type</cell><cell>CW (Infec-</cell><cell>tion/inflammation, PU,</cell><cell>Burn, Trauma, Diabetics)</cell><cell></cell><cell></cell><cell></cell><cell>DFU</cell><cell></cell><cell></cell><cell></cell><cell>SW</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>CW</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>CW</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Lower limb ulcers, DFU and</cell><cell>PU</cell></row><row><cell>Validation methods</cell><cell>Pixel accuracy and IoU</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Accuracy, weighted F1-</cell><cell>score, Confusion matrix</cell><cell></cell><cell></cell><cell>Accuracy, True Positive Rate</cell><cell>(TPR)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>accuracy, weighted preci-</cell><cell>sion, Jaccard Index (JI),</cell><cell>Cohen's K</cell><cell></cell><cell></cell><cell>Intra-and inter-rater reliabil-</cell><cell>ity, accuracy, ROC curves</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Kruskal-Wallis one-way</cell><cell>analysis of variations for</cell><cell>area and depth</cell></row><row><cell>Technology</cell><cell>AI-assisted wound assess-</cell><cell>ment tool with U-Net +</cell><cell>EfficientNet-B2 and U-Net +</cell><cell>MobilenetV2 for tissue clas-</cell><cell>sification and area measure-</cell><cell>ment</cell><cell>Bilinear CNN with VGG16</cell><cell>for wound depth and granu-</cell><cell>lation tissue classification</cell><cell></cell><cell>Edge-based adaptive seg-</cell><cell>mentation for wound image</cell><cell>analysis, with SVM-based</cell><cell>infection detection module</cell><cell></cell><cell></cell><cell>SVM and RF to classify</cell><cell>segments into categories</cell><cell>(wound, purpura, normal</cell><cell>skin, etc.) using SLIC for</cell><cell>segmentation</cell><cell>Superpixels and kmeans</cell><cell>for wound segmentation,</cell><cell>VGG16, InceptionRes-</cell><cell>NetV2, InceptionV2,</cell><cell>ResNet50 for classifica-</cell><cell>tion</cell><cell>Clinical trial of AI-powered,</cell><cell>non-invasive medical device</cell><cell>"Wound Viewer" for wound</cell><cell>evaluation</cell></row><row><cell>Article</cell><cell>[112]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>[113]</cell><cell></cell><cell></cell><cell></cell><cell>[114]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>[115]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>[116]</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>[117]</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 20</head><label>20</label><figDesc>Comparison of different aspects between AI models and traditional wound assessment tools Additionally, while tools like PUSH, BWAT, and Visitrak are designed for specific wound types or require manual interventions, AI models exhibit broader applicability, encompassing diabetic ulcers, vascular ulcers, and other chronic wound etiologies.Despite these advancements, the integration of AI models into clinical practice requires addressing certain challenges. Comprehensive clinical validation is essential, requiring studies that evaluate AI performance in real-world contexts. Moreover, ensuring healthcare professionals are adequately trained to use these tools effectively is critical. Finally, accessible technological infrastructure must be developed to facilitate the adoption of AI systems, particularly in resourcelimited settings.</figDesc><table><row><cell>Aspect</cell><cell>Traditional Tools</cell><cell>AI Models</cell></row><row><cell>Precision</cell><cell>Dependent on the evaluator</cell><cell>Consistent and automated</cell></row><row><cell>Subjectivity</cell><cell>High, variable between users</cell><cell>Fast, Low, based on objective and reproducible data</cell></row><row><cell>Speed</cell><cell>Slow manual evaluations</cell><cell>Fast, real-time processing</cell></row><row><cell>Predictions and Outcomes</cell><cell>Limited</cell><cell>Advanced, includes complications and progression</cell></row><row><cell>Generalization</cell><cell>Specific to certain wound types</cell><cell>Broad clinical applicability</cell></row><row><cell>gies.</cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data and materials availability</head><p>No datasets were generated or analysed during the current study.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary information</head><p>The data that supports the findings of this study are available in the supplementary material of this article.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Information</head><p>The online version contains supplementary material available at https://doi.org/10.1007/s10916-025-02153-8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Author Contributions</head><p>All authors contributed to the study conception and design. Material preparation, data collection and analysis were performed by Lorena Casanova, and David Reifs. The first draft of the manuscript was written by Lorena Casanova and all authors commented on previous versions of the manuscript. All authors read and approved the final manuscript.</p><p>Funding Open Access funding provided thanks to the CRUE-CSIC agreement with Springer Nature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declarations</head><p>Financial Interests The authors declare they have no financial interests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflict of Interest</head><p>The authors declare no Conflict of interest.</p><p>Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecomm ons.org/licenses/by/4.0/.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="34,317.43,528.90,226.82,7.44;34,325.58,538.87,218.67,7.44;34,325.58,548.71,179.55,7.56" xml:id="b0">
	<analytic>
		<title level="a" type="main">Actualización en la validez de las escalas de evaluación de la evolución de heridas</title>
		<author>
			<persName><forename type="first">Elisabet Alguacil</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justo</forename><surname>Rueda López</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M S V</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Heridas y Cicatrización</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="15" to="21" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="34,317.43,558.78,226.84,7.44;34,325.58,568.75,193.08,7.44" xml:id="b1">
	<analytic>
		<title level="a" type="main">Wound healing: cellular mechanisms and pathological outcomes</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">N</forename><surname>Wilkinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Hardman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Open Biology</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="34,317.43,578.71,226.86,7.44;34,325.58,588.67,218.69,7.44;34,325.58,598.63,172.77,7.44" xml:id="b2">
	<monogr>
		<author>
			<persName><forename type="first">]</forename><surname>Internet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">O</forename></persName>
		</author>
		<ptr target="https://www.ncbi.nlm.nih.gov/books/NBK326431" />
		<title level="m">Overview: Chronic wounds. Institute for Quality and Efficiency in Health Care (IQWiG)</title>
		<imprint>
			<biblScope unit="page" from="2024" to="2036" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="34,317.42,608.60,226.83,7.44;34,325.58,618.56,218.64,7.44;34,325.58,628.52,193.90,7.44" xml:id="b3">
	<analytic>
		<title level="a" type="main">Hard-to-Heal Wounds</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mongkornwong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Wongwiwat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Chansanti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sukprasert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Akaranuchat</surname></persName>
		</author>
		<idno type="DOI">10.31584/psumj.2024265285</idno>
		<ptr target="https://doi.org/10.31584/psumj.2024265285" />
	</analytic>
	<monogr>
		<title level="j">PSU Medical Journal</title>
		<imprint>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="34,317.42,638.49,226.85,7.44;34,325.58,648.45,218.69,7.44;34,325.58,658.29,218.32,7.56;34,325.58,668.37,46.07,7.44" xml:id="b4">
	<analytic>
		<title level="a" type="main">A systematic overview of recent methods for non-contact chronic wound analysis</title>
		<author>
			<persName><forename type="first">D</forename><surname>Marijanović</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Filko</surname></persName>
		</author>
		<idno type="DOI">10.3390/app10217613</idno>
		<ptr target="https://doi.org/10.3390/app10217613" />
	</analytic>
	<monogr>
		<title level="j">Applied Sciences (Switzerland)</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">21</biblScope>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="34,317.43,678.34,226.82,7.44;34,325.58,688.18,145.56,7.56" xml:id="b5">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Agale</surname></persName>
		</author>
		<title level="m">Chronic Leg Ulcers : Epidemiology, Aetiopathogenesis, and Management. Ulcers 2013</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="34,317.43,698.26,226.82,7.44;34,325.58,708.23,218.67,7.44" xml:id="b6">
	<monogr>
		<title level="m" type="main">Topical antimicrobial therapy of chronic wounds healing by secondary intention using iodine products</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Leaper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Durani</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="35,70.47,60.34,218.70,7.56;35,70.47,70.42,136.16,7.44" xml:id="b7">
	<analytic>
		<title/>
		<idno type="DOI">10.1111/j.1742-481X.2007.00406.x</idno>
		<ptr target="https://doi.org/10.1111/j.1742-481X.2007.00406.x" />
	</analytic>
	<monogr>
		<title level="j">International Wound Journal</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="361" to="368" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="35,62.31,80.38,226.82,7.44;35,70.47,90.34,218.62,7.44;35,70.47,100.19,198.48,7.56" xml:id="b8">
	<analytic>
		<title level="a" type="main">Wound management for the 21st century: combining effectiveness and efficiency</title>
		<author>
			<persName><forename type="first">C</forename><surname>Lindholm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Searle</surname></persName>
		</author>
		<idno type="DOI">10.1111/iwj.12623</idno>
		<ptr target="https://doi.org/10.1111/iwj.12623" />
	</analytic>
	<monogr>
		<title level="j">International Wound Journal</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="5" to="15" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="35,62.31,110.27,226.82,7.44;35,70.47,120.23,218.70,7.44;35,70.47,130.08,218.58,7.56;35,70.47,140.16,155.10,7.44" xml:id="b9">
	<analytic>
		<title level="a" type="main">A time motion study of manual versus artificial intelligence methods for wound assessment</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Mohammed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Babb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D J</forename><surname>Fraser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mannion</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0271742</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0271742" />
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="35,61.95,150.12,227.18,7.44;35,70.47,160.08,218.69,7.44;35,70.47,170.05,218.69,7.44;35,70.47,180.01,218.67,7.44;35,70.47,189.85,202.42,7.56" xml:id="b10">
	<analytic>
		<title level="a" type="main">Health-related quality of life and chronic wound characteristics among patients with chronic wounds treated in primary care: A cross-sectional study in Singapore</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bajpai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Järbrink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Car</surname></persName>
		</author>
		<idno type="DOI">10.1111/iwj.13708</idno>
		<ptr target="https://doi.org/10.1111/iwj.13708" />
	</analytic>
	<monogr>
		<title level="j">International Wound Journal</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1121" to="1132" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="35,61.95,199.93,227.18,7.44;35,70.47,209.90,218.67,7.44;35,70.47,219.86,218.65,7.44;35,70.47,229.82,218.69,7.44;35,70.47,239.67,218.70,7.56;35,70.47,249.75,93.22,7.44" xml:id="b11">
	<analytic>
		<title level="a" type="main">Incidence and risk factors of diabetic foot ulcer: A population-based diabetic foot cohort (ADFC study)-two-year follow-up study</title>
		<author>
			<persName><forename type="first">L</forename><surname>Yazdanpanah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Shahbazian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Nazari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">R</forename><surname>Arti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ahmadi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Mohammadianinejad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Cheraghian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hesam</surname></persName>
		</author>
		<idno type="DOI">10.1155/2018/7631659</idno>
		<ptr target="https://doi.org/10.1155/2018/7631659" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Endocrinology</title>
		<imprint>
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="35,61.95,259.71,227.18,7.44;35,70.47,269.67,218.68,7.44;35,70.47,279.63,218.68,7.44;35,70.47,289.47,218.12,7.56;35,70.47,299.55,24.47,7.44" xml:id="b12">
	<analytic>
		<title level="a" type="main">The humanistic and economic burden of chronic wounds: A protocol for a systematic review</title>
		<author>
			<persName><forename type="first">K</forename><surname>Järbrink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sönnergren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schmidtchen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bajpai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Car</surname></persName>
		</author>
		<idno type="DOI">10.1186/s13643-016-0400-8</idno>
		<ptr target="https://doi.org/10.1186/s13643-016-0400-8" />
	</analytic>
	<monogr>
		<title level="j">Systematic Reviews</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="35,61.95,309.52,227.21,7.44;35,70.47,319.48,218.64,7.44;35,70.47,329.44,218.67,7.44;35,70.47,339.29,218.67,7.56;35,70.47,349.37,53.71,7.44" xml:id="b13">
	<analytic>
		<title level="a" type="main">Diagnosis and treatment of the invasive extension of bacteria (cellulitis) from chronic wounds utilising point-of-care fluorescence imaging</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Andersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Mcleod</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Steffan</surname></persName>
		</author>
		<idno type="DOI">10.1111/iwj.13696</idno>
		<ptr target="https://doi.org/10.1111/iwj.13696" />
	</analytic>
	<monogr>
		<title level="j">International Wound Journal</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="996" to="1008" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="35,61.95,359.33,227.17,7.44;35,70.47,369.29,218.69,7.44;35,70.47,379.26,218.67,7.44;35,70.47,389.10,218.66,7.56;35,70.47,399.18,144.73,7.44" xml:id="b14">
	<analytic>
		<title level="a" type="main">Toward machine-learning-based decision support in diabetes care: A risk stratification study on diabetic foot ulcer and amputation</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Schäfer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mathisen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Svendsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Engberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">R</forename><surname>Thomsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kirketerp-Møller</surname></persName>
		</author>
		<idno type="DOI">10.3389/fmed.2020.601602</idno>
		<ptr target="https://doi.org/10.3389/fmed.2020.601602" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Medicine</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="35,61.95,409.14,227.18,7.44;35,70.47,419.11,218.66,7.44;35,70.47,429.07,218.68,7.44;35,70.47,438.91,215.32,7.56" xml:id="b15">
	<analytic>
		<title level="a" type="main">Burden of infected diabetic foot ulcers on hospital admissions and costs in a third-level center</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Ros</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Assaloni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Michelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Brunato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Barro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Meloni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Miranda</surname></persName>
		</author>
		<idno type="DOI">10.3390/diabetology5020011</idno>
		<ptr target="https://doi.org/10.3390/diabetology5020011" />
	</analytic>
	<monogr>
		<title level="j">Diabetology</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="141" to="150" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="35,61.95,449.00,227.18,7.44;35,70.47,458.96,218.66,7.44;35,70.47,468.92,218.63,7.44;35,70.47,478.88,218.66,7.44;35,70.47,488.73,218.64,7.56;35,70.47,498.81,29.61,7.44" xml:id="b16">
	<analytic>
		<title level="a" type="main">Towards an ai-based objective prognostic model for quantifying wound healing</title>
		<author>
			<persName><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Goldstone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Eisen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ramachandram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Cassata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D J</forename><surname>Fraser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Ramirez-Garcialuna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Allport</surname></persName>
		</author>
		<idno type="DOI">10.1109/JBHI.2023.3251901</idno>
		<ptr target="https://doi.org/10.1109/JBHI.2023.3251901" />
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Biomedical and Health Informatics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="666" to="677" />
			<date type="published" when="2024">2024</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="35,61.95,508.77,227.17,7.44;35,70.47,518.74,218.70,7.44;35,70.47,528.57,171.76,7.56" xml:id="b17">
	<analytic>
		<title level="a" type="main">The Role of Artificial Intelligence in Chronic Wound Assessment and Management</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ramawat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Nitesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pareek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Wocsi Journal of Medical Science</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="35,61.95,538.65,227.21,7.44;35,70.46,548.62,218.66,7.44;35,70.46,558.58,218.67,7.44;35,70.46,568.54,218.66,7.44;35,70.46,578.50,218.11,7.44;35,70.46,588.47,47.27,7.44" xml:id="b18">
	<analytic>
		<title level="a" type="main">Performance Analysis of Compression Techniques for Chronic Wound Image Transmission Under Smartphone-Enabled Tele-Wound Network</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chakraborty</surname></persName>
		</author>
		<idno type="DOI">10.4018/978-1-7998-8052-3.ch018</idno>
		<ptr target="https://doi.org/10.4018/978-1-7998-8052-3.ch018" />
	</analytic>
	<monogr>
		<title level="j">Research Anthology on Telemedicine Efficacy, Adoption, and Impact on Healthcare Delivery</title>
		<imprint>
			<biblScope unit="page" from="345" to="364" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="35,61.95,598.43,227.11,7.44;35,70.46,608.39,218.68,7.44;35,70.46,618.36,218.66,7.44;35,70.46,628.32,218.67,7.44;35,70.46,638.28,218.67,7.44;35,70.46,648.24,218.67,7.44;35,70.46,658.21,218.66,7.44;35,70.46,668.17,197.70,7.44" xml:id="b19">
	<monogr>
		<title level="m" type="main">The PRISMA 2020 statement: An updated guideline for reporting systematic reviews</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Mckenzie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Bossuyt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Boutron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Mulrow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shamseer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Tetzlaff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Akl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Brennan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Glanville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Grimshaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hróbjartsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Lalu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>Loder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mayo-Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Mcguinness</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Tricco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">A</forename><surname>Welch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Whiting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Moher</surname></persName>
		</author>
		<idno type="DOI">10.1136/bmj.n71</idno>
		<ptr target="https://doi.org/10.1136/bmj.n71" />
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>BMJ Publishing Group</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="35,61.95,678.13,227.06,7.44;35,70.46,688.10,218.67,7.44;35,70.46,698.06,218.67,7.44;35,70.46,708.02,218.68,7.44;35,325.58,60.45,218.62,7.44;35,325.58,70.41,218.68,7.44;35,325.58,80.37,218.68,7.44;35,325.58,90.34,218.36,7.44;35,325.58,100.30,62.40,7.44" xml:id="b20">
	<monogr>
		<title level="m" type="main">PRISMA 2020 explanation and elaboration: Updated guidance and exemplars for reporting systematic reviews</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Page</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Moher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Bossuyt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Boutron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">C</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">D</forename><surname>Mulrow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Shamseer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Tetzlaff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Akl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Brennan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Glanville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Grimshaw</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hróbjartsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Lalu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>Loder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mayo-Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Mcguinness</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Tricco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">A</forename><surname>Welch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Whiting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Mckenzie</surname></persName>
		</author>
		<idno type="DOI">10.1136/bmj.n160</idno>
		<ptr target="https://doi.org/10.1136/bmj.n160" />
		<imprint>
			<date type="published" when="2021">2021</date>
			<publisher>BMJ Publishing Group</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="35,317.07,110.26,227.17,7.44;35,325.58,120.22,218.67,7.44;35,325.58,130.19,218.68,7.44;35,325.58,140.15,218.66,7.44;35,325.58,149.99,218.32,7.56;35,325.58,160.08,202.48,7.44;35,325.58,170.04,87.56,7.44" xml:id="b21">
	<analytic>
		<title level="a" type="main">Quadas-2: A revised tool for the quality assessment of diagnostic accuracy studies</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">F</forename><surname>Whiting</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W S</forename><surname>Rutjes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Westwood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mallett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Deeks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Reitsma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M G</forename><surname>Leeflang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A C</forename><surname>Sterne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M M</forename><surname>Bossuyt</surname></persName>
		</author>
		<idno type="DOI">10.7326/0003-4819-155-8-201110180-00009/SUPPL_FILE/155-8-529-SUPPLEMENT.PDF</idno>
		<ptr target="https://doi.org/10.7326/0003-4819-155-8-201110180-00009/SUPPL_FILE/155-8-529-SUPPLEMENT.PDF" />
	</analytic>
	<monogr>
		<title level="j">Annals of Internal Medicine</title>
		<imprint>
			<biblScope unit="volume">155</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="529" to="536" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="35,317.07,180.00,227.17,7.44;35,325.58,189.96,218.70,7.44;35,325.58,199.93,218.71,7.44;35,325.58,209.77,218.68,7.56;35,325.58,219.85,177.96,7.44" xml:id="b22">
	<analytic>
		<title level="a" type="main">Quality assessment standards in artificial intelligence diagnostic accuracy systematic reviews: a meta-research study</title>
		<author>
			<persName><forename type="first">S</forename><surname>Jayakumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Sounderajah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Normahani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Harling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Markar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ashrafian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Darzi</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41746-021-00544-y</idno>
		<ptr target="https://doi.org/10.1038/s41746-021-00544-y" />
	</analytic>
	<monogr>
		<title level="j">Digital Medicine</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="35,317.07,229.82,227.15,7.44;35,325.58,239.78,218.37,7.44;35,325.58,249.74,204.34,7.44;35,325.58,259.70,191.47,7.44" xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Mishra</surname></persName>
		</author>
		<idno>2024-05-30</idno>
		<ptr target="https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba" />
		<title level="m">Metrics to Evaluate your Machine Learning Algorithm | by Aditya Mishra -Towards Data Science</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="35,317.07,269.67,227.17,7.44;35,325.58,279.62,218.23,7.44;35,325.58,289.58,218.69,7.44;35,325.58,299.55,39.47,7.44" xml:id="b24">
	<monogr>
		<title level="m" type="main">What is matthews correlation coefficient (MCC)?</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Chanbi</surname></persName>
		</author>
		<idno>2024-12-13</idno>
		<ptr target="https://medium.com/@CuttiE_MarU/what-is-matthews-correlation-coefficient-mcc" />
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="35,317.07,309.51,227.18,7.44;35,325.58,319.47,218.69,7.44;35,325.58,329.32,218.70,7.56;35,325.58,339.41,124.93,7.44" xml:id="b25">
	<analytic>
		<title level="a" type="main">Evaluation measures of the classification performance of imbalanced data sets</title>
		<author>
			<persName><forename type="first">Q</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-04962-0_53</idno>
		<idno>978-3-642-04962-0_53</idno>
		<ptr target="https://doi.org/10.1007/" />
	</analytic>
	<monogr>
		<title level="j">Communications in Computer and Information Science</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="461" to="471" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="35,317.07,349.37,227.19,7.44;35,325.58,359.33,218.67,7.44;35,325.58,369.18,218.12,7.56;35,325.58,379.26,92.51,7.44" xml:id="b26">
	<analytic>
		<title level="a" type="main">Towards a guideline for evaluation metrics in medical image segmentation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Soto-Rey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Kramer</surname></persName>
		</author>
		<idno type="DOI">10.1186/s13104-022-06096-y</idno>
		<idno type="arXiv">arXiv:2202.05273</idno>
		<ptr target="https://doi.org/10.1186/s13104-022-06096-y" />
	</analytic>
	<monogr>
		<title level="j">BMC Research Notes</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="35,317.08,389.22,227.20,7.44;35,325.58,399.19,218.67,7.44;35,325.58,409.15,218.67,7.44;35,325.58,418.99,218.66,7.56;35,325.58,429.07,149.03,7.44" xml:id="b27">
	<analytic>
		<title level="a" type="main">Estimation of an interrater intra-class correlation coefficient that overcomes common assumption violations in the assessment of health measurement scales</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Bobak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Barr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>O'malley</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12874-018-0550-6</idno>
		<ptr target="https://doi.org/10.1186/s12874-018-0550-6" />
	</analytic>
	<monogr>
		<title level="j">BMC Medical Research Methodology</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="35,317.07,439.04,227.20,7.44;35,325.58,449.00,218.68,7.44;35,325.58,458.96,218.66,7.44;35,325.58,468.81,199.07,7.56" xml:id="b28">
	<analytic>
		<title level="a" type="main">Automated tissue classification framework for reproducible chronic wound assessment</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Manohar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Achar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chakraborty</surname></persName>
		</author>
		<idno type="DOI">10.1155/2014/851582</idno>
		<ptr target="https://doi.org/10.1155/2014/851582" />
	</analytic>
	<monogr>
		<title level="j">BioMed Research International</title>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="35,317.07,478.89,227.17,7.44;35,325.58,488.85,218.70,7.44;35,325.58,498.81,218.68,7.44;35,325.58,508.66,218.67,7.56;35,325.58,518.74,145.72,7.44" xml:id="b29">
	<analytic>
		<title level="a" type="main">Fully automated wound tissue segmentation using deep learning on mobile devices: Cohort study</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ramachandram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Ramirez-Garcialuna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D J</forename><surname>Fraser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Martínez-Jiménez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Arriaga-Caballero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Allport</surname></persName>
		</author>
		<idno type="DOI">10.2196/36977</idno>
		<ptr target="https://doi.org/10.2196/36977" />
	</analytic>
	<monogr>
		<title level="j">JMIR mHealth and uHealth</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="35,317.07,528.69,227.16,7.44;35,325.58,538.66,218.70,7.44;35,325.58,548.62,218.61,7.44;35,325.58,558.46,218.32,7.56;35,325.58,568.55,67.36,7.44" xml:id="b30">
	<analytic>
		<title level="a" type="main">Tissue classification and segmentation of pressure injuries using convolutional neural networks</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zahia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sierra-Sosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Garcia-Zapirain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Elmaghraby</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cmpb.2018.02.018</idno>
		<idno>02.018</idno>
		<ptr target="https://doi.org/10.1016/j.cmpb" />
	</analytic>
	<monogr>
		<title level="j">Computer Methods and Programs in Biomedicine</title>
		<imprint>
			<biblScope unit="volume">159</biblScope>
			<biblScope unit="page" from="51" to="58" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="35,317.07,578.51,227.18,7.44;35,325.58,588.47,218.67,7.44;35,325.58,598.32,218.36,7.56;35,325.58,608.40,105.89,7.44" xml:id="b31">
	<analytic>
		<title level="a" type="main">Wound image evaluation with machine learning</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Veredas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Luque-Baena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Martín-Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Morilla-Herrera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Morente</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neucom.2014.12.091</idno>
		<ptr target="https://doi.org/10.1016/j.neucom.2014.12.091" />
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">164</biblScope>
			<biblScope unit="page" from="112" to="122" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="35,317.07,618.36,227.17,7.44;35,325.58,628.32,218.65,7.44;35,325.58,638.29,218.66,7.44;35,325.58,648.13,218.12,7.56;35,325.58,658.21,24.47,7.44" xml:id="b32">
	<analytic>
		<title level="a" type="main">Classification of pressure ulcer tissues with 3d convolutional neural network</title>
		<author>
			<persName><forename type="first">B</forename><surname>García-Zapirain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Elmogy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>El-Baz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Elmaghraby</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11517-018-1835-y</idno>
		<ptr target="https://doi.org/10.1007/s11517-018-1835-y" />
	</analytic>
	<monogr>
		<title level="j">Medical and Biological Engineering and Computing</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="2245" to="2258" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="35,317.07,668.17,227.19,7.44;35,325.58,678.14,218.66,7.44;35,325.58,688.10,218.68,7.44;35,325.58,698.06,218.67,7.44;36,460.33,34.22,40.23,7.57" xml:id="b33">
	<monogr>
		<title level="m" type="main">Clinical validation of an artificial intelligence-enabled wound imaging mobile application in dia</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">M</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">T</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R C</forename><surname>Chong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W L</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chandrasekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">J</forename><surname>Lo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2025">2025</date>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="36,70.47,60.34,218.61,7.56;36,70.47,70.42,114.91,7.44" xml:id="b34">
	<analytic>
		<title level="a" type="main">betic foot ulcers</title>
		<idno type="DOI">10.1111/iwj.13603</idno>
		<ptr target="https://doi.org/10.1111/iwj.13603" />
	</analytic>
	<monogr>
		<title level="j">International Wound Journal</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="114" to="124" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="36,61.95,80.38,227.17,7.44;36,70.47,90.34,218.68,7.44;36,70.47,100.31,218.69,7.44;36,70.47,110.27,184.50,7.44" xml:id="b35">
	<analytic>
		<title level="a" type="main">Quantifying digital ulcers in systemic sclerosis: reliability of digital planimetry in measuring lesion size</title>
		<author>
			<persName><forename type="first">V</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wilkinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Herrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Dinsdale</surname></persName>
		</author>
		<idno type="DOI">10.1002/acr.23300</idno>
		<ptr target="https://doi.org/10.1002/acr.23300" />
	</analytic>
	<monogr>
		<title level="j">Arthritis Care and Research</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="36,61.95,120.23,227.17,7.44;36,70.47,130.19,218.67,7.44;36,70.47,140.16,218.68,7.44;36,70.47,150.00,218.70,7.56;36,70.47,160.08,81.13,7.44" xml:id="b36">
	<analytic>
		<title level="a" type="main">Experimental study on wound area measurement with mobile devices</title>
		<author>
			<persName><forename type="first">F</forename><surname>Ferreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>Pires</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Ponciano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V</forename><surname>Villasana</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Zdravevski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Lameski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Chorbev</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mihajlov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Trajkovik</surname></persName>
		</author>
		<idno type="DOI">10.3390/s21175762</idno>
		<ptr target="https://doi.org/10.3390/s21175762" />
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="36,61.95,170.05,227.17,7.44;36,70.47,180.01,218.66,7.44;36,70.47,189.97,218.67,7.44;36,70.47,199.82,218.66,7.56;36,70.47,209.90,141.94,7.44" xml:id="b37">
	<analytic>
		<title level="a" type="main">Internet service for wound area measurement using digital planimetry with adaptive calibration and image segmentation with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">P</forename><surname>Foltynski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ladyzynski</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.bbe.2022.11.004</idno>
		<ptr target="https://doi.org/10.1016/j.bbe.2022.11.004" />
	</analytic>
	<monogr>
		<title level="j">Biocybernetics and Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="17" to="29" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="36,61.95,219.86,227.19,7.44;36,70.47,229.82,218.70,7.44;36,70.47,239.79,218.67,7.44;36,70.47,249.63,218.67,7.56;36,70.47,259.71,102.04,7.44" xml:id="b38">
	<analytic>
		<title level="a" type="main">Multi-view data augmentation to improve wound segmentation on 3d surface model by deep learning</title>
		<author>
			<persName><forename type="first">R</forename><surname>Niri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Gutierrez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Douzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Treuillet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Castaneda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Hernandez</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2021.3130784</idno>
		<ptr target="https://doi.org/10.1109/ACCESS.2021.3130784" />
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="157628" to="157638" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="36,61.95,269.67,227.21,7.44;36,70.47,279.63,218.66,7.44;36,70.47,289.59,218.67,7.44;36,70.47,299.43,218.66,7.56;36,70.47,309.52,191.81,7.44" xml:id="b39">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for wound detection: The role of artificial intelligence in wound care</title>
		<author>
			<persName><forename type="first">N</forename><surname>Ohura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mitsuno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sakisaka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Terabe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Morishige</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Uchiyama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Okoshi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Shinji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Takushima</surname></persName>
		</author>
		<idno type="DOI">10.12968/jowc.2019.28.sup10.s13</idno>
		<ptr target="https://doi.org/10.12968/jowc.2019.28.sup10.s13" />
	</analytic>
	<monogr>
		<title level="j">Journal of Wound Care</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="13" to="24" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="36,61.95,319.48,227.21,7.44;36,70.47,329.44,218.69,7.44;36,70.47,339.40,218.68,7.44;36,70.47,349.25,218.64,7.56;36,70.47,359.33,25.38,7.44" xml:id="b40">
	<analytic>
		<title level="a" type="main">Detect-and-segment: A deep learning approach to automate wound image segmentation</title>
		<author>
			<persName><forename type="first">G</forename><surname>Scebba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Catanzaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Mihai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Distler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Berli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Karlen</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.imu.2022.100884</idno>
		<ptr target="https://doi.org/10.1016/j.imu.2022.100884" />
	</analytic>
	<monogr>
		<title level="j">Informatics in Medicine Unlocked</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page">100884</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="36,61.95,369.29,227.20,7.44;36,70.47,379.26,218.63,7.44;36,70.47,389.22,218.65,7.44;36,70.47,399.18,181.92,7.44" xml:id="b41">
	<monogr>
		<title level="m" type="main">Fully automatic wound segmentation with deep convolutional neural networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Anisuzzaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Dhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rostami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Niezgoda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-020-78799-w</idno>
		<ptr target="https://doi.org/10.1038/s41598-020-78799-w" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="36,61.95,409.14,227.11,7.44;36,70.47,419.11,218.67,7.44;36,70.47,429.07,218.65,7.44;36,70.47,438.91,218.66,7.56;36,70.47,449.00,44.42,7.44" xml:id="b42">
	<analytic>
		<title level="a" type="main">Image segmentation using transfer learning and fast r-cnn for diabetic foot wound treatments</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">N</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">J</forename><surname>Sheen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Tseng</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpubh.2022.969846</idno>
		<ptr target="https://doi.org/10.3389/fpubh.2022.969846" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Public Health</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="36,61.95,458.96,227.20,7.44;36,70.47,468.92,218.67,7.44;36,70.47,478.88,218.67,7.44;36,70.47,488.73,218.70,7.56;36,70.47,498.81,137.10,7.44" xml:id="b43">
	<analytic>
		<title level="a" type="main">Fuzzy spectral clustering for automated delineation of chronic wound region using digital images</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Dhane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Maity</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mungle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Achar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kolekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chakraborty</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.compbiomed.2017.04.004</idno>
		<ptr target="https://doi.org/10.1016/j.compbiomed.2017.04.004" />
	</analytic>
	<monogr>
		<title level="j">Computers in Biology and Medicine</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="551" to="560" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="36,61.95,508.77,227.18,7.44;36,70.47,518.74,218.67,7.44;36,70.47,528.57,218.32,7.56;36,70.47,538.65,82.42,7.44" xml:id="b44">
	<analytic>
		<title level="a" type="main">Wound segmentation network based on location information enhancement</title>
		<author>
			<persName><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jin</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2019.2925689</idno>
		<ptr target="https://doi.org/10.1109/ACCESS" />
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="87223" to="87232" />
			<date type="published" when="2019">2019. 2019.2925689</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="36,61.95,548.62,227.20,7.44;36,70.47,558.58,218.67,7.44;36,70.47,568.54,218.69,7.44;36,70.47,578.39,218.65,7.56;36,70.47,588.47,48.65,7.44" xml:id="b45">
	<analytic>
		<title level="a" type="main">Segmentation and measurement of chronic wounds for bioprinting</title>
		<author>
			<persName><forename type="first">P</forename><surname>Gholami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Ahmadi-Pajouh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Abolftahi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hamarneh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kayvanrad</surname></persName>
		</author>
		<idno type="DOI">10.1109/JBHI.2017.2743526</idno>
		<ptr target="https://doi.org/10.1109/JBHI.2017.2743526" />
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Biomedical and Health Informatics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1269" to="1277" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="36,61.95,598.43,227.15,7.44;36,70.47,608.39,218.68,7.44;36,70.47,618.36,218.67,7.44;36,70.47,628.20,178.16,7.56" xml:id="b46">
	<analytic>
		<title level="a" type="main">Boundary determination of foot ulcer images by applying the associative hierarchical random field framework</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Agu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Strong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tulu</surname></persName>
		</author>
		<idno type="DOI">10.1117/1.jmi.6.2.024002</idno>
		<ptr target="https://doi.org/10.1117/1.jmi.6.2.024002" />
	</analytic>
	<monogr>
		<title level="j">Journal of Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="36,61.95,638.28,227.17,7.44;36,70.47,648.24,218.68,7.44;36,70.47,658.09,218.36,7.56;36,70.47,668.17,126.39,7.44" xml:id="b47">
	<analytic>
		<title level="a" type="main">Automatic measurement of pressure ulcers using support vector machines and grabcut</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H L</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M C</forename><surname>Machado</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cmpb.2020.105867</idno>
		<ptr target="https://doi.org/10.1016/j.cmpb.2020.105867" />
	</analytic>
	<monogr>
		<title level="j">Computer Methods and Programs in Biomedicine</title>
		<imprint>
			<biblScope unit="volume">200</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="36,61.95,678.13,227.19,7.44;36,70.47,688.10,218.67,7.44;36,70.47,698.06,218.65,7.44;36,70.47,708.02,218.67,7.44;36,325.58,60.33,218.32,7.56;36,325.58,70.41,69.70,7.44" xml:id="b48">
	<analytic>
		<title level="a" type="main">Diabetic foot ulcer segmentation using logistic regression, dbscan clustering and morphological operators</title>
		<author>
			<persName><forename type="first">A</forename><surname>Heras-Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Valdes-Santiago</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Leon-Mecias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L B</forename><surname>Diaz-Romañach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Mesejo-Chiong</surname></persName>
		</author>
		<idno type="DOI">10.5565/REV/ELCVIA.1413</idno>
		<ptr target="https://doi.org/10.5565/REV/ELCVIA.1413" />
	</analytic>
	<monogr>
		<title level="j">Electronic Letters on Computer Vision and Image Analysis</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="23" to="39" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="36,317.07,80.37,227.18,7.44;36,325.58,90.34,218.68,7.44;36,325.58,100.30,218.68,7.44;36,325.58,110.26,218.69,7.44;36,325.58,120.11,185.70,7.56" xml:id="b49">
	<analytic>
		<title level="a" type="main">Effectiveness of semi-supervised active learning in automated wound image segmentation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Curti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Merli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Zengarini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Giampieri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Merlotti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dall'olio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Marcelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bianchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Castellani</surname></persName>
		</author>
		<idno type="DOI">10.3390/ijms24010706</idno>
		<ptr target="https://doi.org/10.3390/ijms24010706" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Molecular Sciences</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="36,317.07,130.19,227.20,7.44;36,325.58,140.15,218.67,7.44;36,325.58,150.11,218.68,7.44;36,325.58,159.96,218.65,7.56;36,325.58,170.04,16.92,7.44" xml:id="b50">
	<analytic>
		<title level="a" type="main">Segmentation of chronic wound areas by clustering techniques using selected color space</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Yadav</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Manohar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chakraborty</surname></persName>
		</author>
		<idno type="DOI">10.1166/jmihi.2013.1124</idno>
		<ptr target="https://doi.org/10.1166/jmihi.2013.1124" />
	</analytic>
	<monogr>
		<title level="j">Journal of Medical Imaging and Health Informatics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="22" to="29" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="36,317.07,180.00,227.16,7.44;36,325.58,189.96,218.65,7.44;36,325.58,199.93,218.66,7.44;36,325.58,209.77,218.66,7.56;36,325.58,219.85,145.93,7.44" xml:id="b51">
	<analytic>
		<title level="a" type="main">Identifying the optimal threshold for image segmentation using pso and its application to chronic wound assessment</title>
		<author>
			<persName><forename type="first">W</forename><surname>Atisattapong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chansri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Somboonbadeebut</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Songkaew</surname></persName>
		</author>
		<idno type="DOI">10.18178/joig.10.3.116-121</idno>
		<ptr target="https://doi.org/10.18178/joig.10.3.116-121" />
	</analytic>
	<monogr>
		<title level="j">Journal of Image and Graphics(United Kingdom)</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="116" to="121" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="36,317.07,229.82,227.20,7.44;36,325.58,239.78,218.67,7.44;36,325.58,249.74,218.68,7.44;36,325.58,259.59,218.16,7.57;36,325.58,269.68,40.47,7.44" xml:id="b52">
	<analytic>
		<title level="a" type="main">Spectral clustering for unsupervised segmentation of lower extremity wound beds using optical images</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Dhane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Achar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Bar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sanyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chakraborty</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10916-016-0554-x</idno>
		<ptr target="https://doi.org/10.1007/s10916-016-0554-x" />
	</analytic>
	<monogr>
		<title level="j">Journal of Medical Systems</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="36,317.07,279.63,227.20,7.44;36,325.58,289.59,218.70,7.44;36,325.58,299.56,218.65,7.44;36,325.58,309.52,92.56,7.44" xml:id="b53">
	<monogr>
		<title level="m" type="main">Wound intensity correction and segmentation with convolutional neural networks</title>
		<author>
			<persName><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Serikawa</surname></persName>
		</author>
		<idno type="DOI">10.1002/cpe</idno>
		<ptr target="https://doi.org/10.1002/cpe" />
		<imprint>
			<date type="published" when="2016">2016</date>
			<publisher>Wiley Online Library</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="36,317.08,319.48,227.13,7.44;36,325.58,329.44,218.67,7.44;36,325.58,339.29,218.66,7.56;36,325.58,349.37,149.03,7.44" xml:id="b54">
	<analytic>
		<title level="a" type="main">Efficient detection of woundbed and peripheral skin with statistical colour models</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Veredas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mesa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Morente</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11517-014-1240-0</idno>
		<ptr target="https://doi.org/10.1007/s11517-014-1240-0" />
	</analytic>
	<monogr>
		<title level="j">Medical and Biological Engineering and Computing</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="345" to="359" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="36,317.07,359.33,227.18,7.44;36,325.58,369.30,218.67,7.44;36,325.58,379.26,218.68,7.44;36,325.58,389.10,218.66,7.56;36,325.58,399.18,48.65,7.44" xml:id="b55">
	<analytic>
		<title level="a" type="main">Robust methods for real-time diabetic foot ulcer detection and localization on mobile devices</title>
		<author>
			<persName><forename type="first">M</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Reeves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rajbhandari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Yap</surname></persName>
		</author>
		<idno type="DOI">10.1109/JBHI.2018.2868656</idno>
		<ptr target="https://doi.org/10.1109/JBHI.2018.2868656" />
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Biomedical and Health Informatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="1730" to="1741" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="36,317.07,409.15,227.13,7.44;36,325.58,419.11,218.69,7.44;36,325.58,429.07,218.60,7.44;36,325.58,438.92,218.70,7.56;36,325.58,449.00,126.41,7.44" xml:id="b56">
	<analytic>
		<title level="a" type="main">Semantic segmentation of smartphone wound images: Comparative analysis of ahrf and cnn-based approaches</title>
		<author>
			<persName><forename type="first">A</forename><surname>Wagh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Agu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Strong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tulu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lindsay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2020.3014175</idno>
		<ptr target="https://doi.org/10.1109/ACCESS.2020.3014175" />
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="181590" to="181604" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="36,317.07,458.96,227.17,7.44;36,325.58,468.92,218.66,7.44;36,325.58,478.77,218.68,7.56;36,325.58,488.85,102.04,7.44" xml:id="b57">
	<analytic>
		<title level="a" type="main">A mobile app for wound localization using deep learning</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Anisuzzaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Niezgoda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2022.3179137</idno>
		<ptr target="https://doi.org/10.1109/ACCESS.2022.3179137" />
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="61398" to="61409" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="36,317.07,498.81,227.17,7.44;36,325.58,508.78,218.69,7.44;36,325.58,518.74,218.69,7.44;36,325.58,528.57,218.36,7.56;36,325.58,538.66,95.54,7.44" xml:id="b58">
	<analytic>
		<title level="a" type="main">Dfunet: Convolutional neural networks for diabetic foot ulcer classification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Reeves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rajbhandari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Spragg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Yap</surname></persName>
		</author>
		<idno type="DOI">10.1109/tetci.2018.2866254</idno>
		<ptr target="https://doi.org/10.1109/tetci.2018.2866254" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Emerging Topics in Computational Intelligence</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="728" to="739" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="36,317.07,548.62,227.15,7.44;36,325.58,558.58,218.68,7.44;36,325.58,568.54,218.66,7.44;36,325.58,578.39,218.15,7.56;36,325.58,588.47,46.58,7.44" xml:id="b59">
	<analytic>
		<title level="a" type="main">Dfu-qutnet: diabetic foot ulcer classification using novel deep convolutional neural network</title>
		<author>
			<persName><forename type="first">L</forename><surname>Alzubaidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Fadhel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Oleiwi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Al-Shamma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11042-019-07820-w</idno>
		<ptr target="https://doi.org/10.1007/s11042-019-07820-w" />
	</analytic>
	<monogr>
		<title level="j">Multimedia Tools and Applications</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="15655" to="15677" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="36,317.07,598.43,227.18,7.44;36,325.58,608.40,218.68,7.44;36,325.58,618.36,218.70,7.44;36,325.58,628.20,218.32,7.56;36,325.58,638.28,95.21,7.44" xml:id="b60">
	<analytic>
		<title level="a" type="main">Recognition of ischaemia and infection in diabetic foot ulcers: Dataset and techniques</title>
		<author>
			<persName><forename type="first">M</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Reeves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rajbhandari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Yap</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.compbiomed.2020.103616</idno>
		<ptr target="https://doi.org/10.1016/j.compbiomed.2020.103616" />
	</analytic>
	<monogr>
		<title level="j">Computers in Biology and Medicine</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="36,317.07,648.25,227.08,7.44;36,325.58,658.21,218.67,7.44;36,325.58,668.05,218.28,7.56;36,325.58,678.14,94.11,7.44" xml:id="b61">
	<analytic>
		<title level="a" type="main">Classification of diabetic foot ulcers using class knowledge banks</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Xiang</surname></persName>
		</author>
		<idno type="DOI">10.3389/fbioe.2021.811028</idno>
		<ptr target="https://doi.org/10.3389/fbioe.2021.811028" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Bioengineering and Biotechnology</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="36,317.07,688.10,227.17,7.44;36,325.58,698.06,218.69,7.44;36,325.58,708.02,218.68,7.44;37,492.45,34.22,8.05,7.57;37,70.47,60.34,218.15,7.56;37,70.47,70.42,44.70,7.44" xml:id="b62">
	<analytic>
		<title level="a" type="main">Multi-modal wound classification using wound image and location by deep neural network</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Anisuzzaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Rostami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Niezgoda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-022-21813-0</idno>
		<idno>41598- 022-21813-0</idno>
		<ptr target="https://doi.org/10.1038/s" />
	</analytic>
	<monogr>
		<title level="j">Sci-29 entific Reports</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="37,61.95,80.38,227.19,7.44;37,70.47,90.34,218.68,7.44;37,70.47,100.19,218.35,7.56;37,70.47,110.27,77.67,7.44" xml:id="b63">
	<analytic>
		<title level="a" type="main">A deep learning approach for diabetic foot ulcer classification and recognition</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ahsan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Naz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Ehsan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sikandar</surname></persName>
		</author>
		<idno type="DOI">10.3390/info14010036</idno>
		<ptr target="https://doi.org/10.3390/info14010036" />
	</analytic>
	<monogr>
		<title level="j">Information (Switzerland)</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="37,61.95,120.23,227.21,7.44;37,70.47,130.19,218.68,7.44;37,70.47,140.16,218.66,7.44;37,70.47,150.00,218.33,7.56;37,70.47,160.08,58.07,7.44" xml:id="b64">
	<analytic>
		<title level="a" type="main">An enhanced diabetic foot ulcer classification approach using glcm and deep convolution neural network</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Ismael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Al-A'araji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Shukur</surname></persName>
		</author>
		<idno type="DOI">10.33640/2405-609X.3268</idno>
		<ptr target="https://doi.org/10.33640/2405-609X.3268" />
	</analytic>
	<monogr>
		<title level="j">Karbala International Journal of Modern Science</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="682" to="691" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="37,61.95,170.05,227.17,7.44;37,70.47,180.01,218.67,7.44;37,70.47,189.85,218.69,7.56;37,70.47,199.93,218.19,7.44" xml:id="b65">
	<analytic>
		<title level="a" type="main">Automated detection of infection in diabetic foot ulcer images using convolutional neural network</title>
		<author>
			<persName><forename type="first">P</forename><surname>Protik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M A</forename><surname>Rahaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Saha</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-981-19-8032-9_40</idno>
		<ptr target="https://doi.org/10.1007/978-981-19-8032-9_40" />
	</analytic>
	<monogr>
		<title level="m">Lecture Notes in Electrical Engineering 980 LNEE</title>
		<imprint>
			<date type="published" when="2023">2023</date>
			<biblScope unit="page" from="565" to="576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="37,61.95,209.90,227.18,7.44;37,70.46,219.86,218.67,7.44;37,70.46,229.82,218.69,7.44;37,70.46,239.67,218.30,7.56;37,70.47,249.75,29.61,7.44" xml:id="b66">
	<analytic>
		<title level="a" type="main">Simultaneous segmentation and classification of pressure injury image data using mask-r-cnn</title>
		<author>
			<persName><forename type="first">M</forename><surname>Swerdlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Guler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yaakov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Armstrong</surname></persName>
		</author>
		<idno type="DOI">10.1155/2023/3858997</idno>
		<ptr target="https://doi.org/10.1155/2023/3858997" />
	</analytic>
	<monogr>
		<title level="j">Computational and Mathematical Methods in Medicine</title>
		<imprint>
			<biblScope unit="volume">2023</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="37,61.95,259.71,227.18,7.44;37,70.47,269.67,218.67,7.44;37,70.47,279.63,218.68,7.44;37,70.47,289.47,218.67,7.56;37,70.47,299.55,21.15,7.44" xml:id="b67">
	<analytic>
		<title level="a" type="main">Recognition of ischaemia and infection in diabetic foot ulcer: A deep convolutional neural network based approach</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Mishra</surname></persName>
		</author>
		<idno type="DOI">10.1002/ima.22598</idno>
		<ptr target="https://doi.org/10.1002/ima.22598" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Imaging Systems and Technology</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="192" to="208" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="37,61.95,309.52,227.18,7.44;37,70.47,319.48,218.68,7.44;37,70.47,329.44,218.68,7.44;37,70.47,339.29,173.24,7.56" xml:id="b68">
	<analytic>
		<title level="a" type="main">Comparison of hybrid convolutional neural networks models for diabetic foot ulcer classification</title>
		<author>
			<persName><forename type="first">L</forename><surname>Alzubaidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A</forename><surname>Abbood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Fadhel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Al-Shamma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Engineering Science and Technology</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<date type="published" when="2001">2001-2017 (2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="37,61.95,349.37,227.19,7.44;37,70.47,359.33,218.68,7.44;37,70.47,369.17,218.33,7.56;37,70.47,379.26,42.34,7.44" xml:id="b69">
	<analytic>
		<title level="a" type="main">Fusion of hand-crafted and deep features for automatic diabetic foot ulcer classification</title>
		<author>
			<persName><forename type="first">N</forename><surname>Al-Garaawi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Harbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Morris</surname></persName>
		</author>
		<idno type="DOI">10.18421/TEM113-10</idno>
		<ptr target="https://doi.org/10.18421/TEM113-10" />
	</analytic>
	<monogr>
		<title level="j">TEM Journal</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1055" to="1064" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="37,61.95,389.22,227.17,7.44;37,70.47,399.18,218.70,7.44;37,70.47,409.14,218.69,7.44;37,70.47,418.99,218.67,7.56;37,70.47,429.07,90.74,7.44" xml:id="b70">
	<analytic>
		<title level="a" type="main">Multiclass wound image classification using an ensemble deep cnn-based classifier</title>
		<author>
			<persName><forename type="first">B</forename><surname>Rostami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Anisuzzaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Niezgoda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.compbiomed.2021.104536</idno>
		<ptr target="https://doi.org/10.1016/j.compbiomed.2021.104536" />
	</analytic>
	<monogr>
		<title level="j">Computers in Biology and Medicine</title>
		<imprint>
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="37,61.95,439.03,227.19,7.44;37,70.47,449.00,218.65,7.44;37,70.47,458.84,218.65,7.56;37,70.47,468.92,184.01,7.44" xml:id="b71">
	<analytic>
		<title level="a" type="main">Diabetic foot ulcer ischemia and infection classification using efficientnet deep learning models</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Agu</surname></persName>
		</author>
		<idno type="DOI">10.1109/OJEMB.2022.3219725</idno>
		<ptr target="https://doi.org/10.1109/OJEMB.2022.3219725" />
	</analytic>
	<monogr>
		<title level="j">IEEE Open Journal of Engineering in Medicine and Biology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="189" to="201" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="37,61.95,478.88,227.19,7.44;37,70.47,488.85,218.66,7.44;37,70.47,498.69,218.65,7.56;37,70.47,508.77,189.89,7.44" xml:id="b72">
	<analytic>
		<title level="a" type="main">Constructing inpatient pressure injury prediction models using machine learning techniques</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">L</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.1097/CIN.0000000000000604</idno>
		<ptr target="https://doi.org/10.1097/CIN.0000000000000604" />
	</analytic>
	<monogr>
		<title level="j">CIN -Computers Informatics Nursing</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="415" to="423" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="37,61.95,518.74,227.19,7.44;37,70.47,528.69,218.67,7.44;37,70.47,538.65,218.66,7.44;37,70.47,548.50,126.76,7.56" xml:id="b73">
	<analytic>
		<title level="a" type="main">Pressure ulcer injury in unstructured clinical notes: Detection and interpretation. AMIA</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sotoodeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">H</forename><surname>Gero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Hertzberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Symposium proceedings. AMIA Symposium</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="1160" to="1169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="37,61.95,558.58,227.20,7.44;37,70.47,568.54,218.69,7.44;37,70.47,578.39,218.70,7.56;37,70.47,588.47,99.47,7.44" xml:id="b74">
	<analytic>
		<title level="a" type="main">Applying of decision tree analysis to risk factors associated with pressure ulcers in long-term care facilities</title>
		<author>
			<persName><forename type="first">M</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.4258/hir.2017.23.1.43</idno>
		<ptr target="https://doi.org/10.4258/hir.2017.23.1.43" />
	</analytic>
	<monogr>
		<title level="j">Healthcare Informatics Research</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="43" to="52" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="37,61.95,598.43,227.17,7.44;37,70.47,608.39,218.67,7.44;37,70.47,618.24,218.36,7.56;37,70.47,628.32,103.96,7.44" xml:id="b75">
	<analytic>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C B H</forename><surname>Ferreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Ferreira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H G</forename><surname>Barbosa</surname></persName>
		</author>
		<idno type="DOI">10.1049/htl.2014.0076</idno>
		<ptr target="https://doi.org/10.1049/htl.2014.0076" />
	</analytic>
	<monogr>
		<title level="m">Non-invasive method to analyse the risk of developing diabetic foot</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="109" to="113" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="37,61.95,638.28,227.19,7.44;37,70.47,648.24,218.67,7.44;37,70.47,658.21,218.67,7.44;37,70.47,668.05,218.32,7.56;37,70.47,678.13,63.00,7.44" xml:id="b76">
	<analytic>
		<title level="a" type="main">Development of a deep learning-based tool to assist wound classification</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">P C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Perng</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.bjps.2023.01.030</idno>
		<idno>01.030</idno>
		<ptr target="https://doi.org/10.1016/j.bjps.2023" />
	</analytic>
	<monogr>
		<title level="j">Journal of Plastic, Reconstructive and Aesthetic Surgery</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="89" to="97" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="37,61.95,688.10,227.21,7.44;37,70.47,698.06,218.66,7.44;37,325.58,60.33,218.68,7.56;37,325.58,70.41,114.83,7.44" xml:id="b77">
	<analytic>
		<title level="a" type="main">Fusionsegnet: Fusing global foot features and local wound features to diagnose diabetic foot</title>
		<author>
			<persName><forename type="first">T</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.compbiomed.2022.106456</idno>
		<ptr target="https://doi.org/10.1016/j.compbiomed.2022.106456" />
	</analytic>
	<monogr>
		<title level="j">Computers in Biology and Medicine</title>
		<imprint>
			<biblScope unit="volume">152</biblScope>
			<biblScope unit="page">106456</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="37,317.07,80.37,227.18,7.44;37,325.58,90.34,218.68,7.44;37,325.58,100.18,218.34,7.56;37,325.58,110.27,100.73,7.44" xml:id="b78">
	<analytic>
		<title level="a" type="main">The enlightening role of explainable artificial intelligence in chronic wound classification</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sarp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kuzlu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Cali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Guler</surname></persName>
		</author>
		<idno type="DOI">10.3390/electronics10121406</idno>
		<ptr target="https://doi.org/10.3390/electronics10121406" />
	</analytic>
	<monogr>
		<title level="j">Electronics (Switzerland)</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="37,317.07,120.23,227.19,7.44;37,325.58,130.19,218.68,7.44;37,325.58,140.16,218.67,7.44;37,325.58,150.00,218.33,7.56;37,325.58,160.08,46.55,7.44" xml:id="b79">
	<analytic>
		<title level="a" type="main">Construction and validation of an image discrimination algorithm to discriminate necrosis from wounds in pressure ulcers</title>
		<author>
			<persName><forename type="first">S</forename><surname>Sakakibara</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Takekawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Takekawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Nagai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Terashi</surname></persName>
		</author>
		<idno type="DOI">10.3390/jcm12062194</idno>
		<ptr target="https://doi.org/10.3390/jcm12062194" />
	</analytic>
	<monogr>
		<title level="j">Journal of Clinical Medicine</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="37,317.08,170.05,227.18,7.44;37,325.58,180.01,218.68,7.44;37,325.58,189.97,218.66,7.44;37,325.58,199.82,218.33,7.56;37,325.58,209.90,46.07,7.44" xml:id="b80">
	<analytic>
		<title level="a" type="main">Towards a better understanding of transfer learning for medical imaging: A case study</title>
		<author>
			<persName><forename type="first">L</forename><surname>Alzubaidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Fadhel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Al-Shamma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Santamaría</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Oleiwi</surname></persName>
		</author>
		<idno type="DOI">10.3390/app10134523</idno>
		<ptr target="https://doi.org/10.3390/app10134523" />
	</analytic>
	<monogr>
		<title level="j">Applied Sciences (Switzerland)</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="37,317.07,219.86,227.11,7.44;37,325.58,229.82,218.66,7.44;37,325.58,239.67,218.37,7.56;37,325.58,249.75,125.57,7.44" xml:id="b81">
	<analytic>
		<title level="a" type="main">Yolobased deep learning model for pressure ulcer detection and classification</title>
		<author>
			<persName><forename type="first">B</forename><surname>Aldughayfiq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Ashfaq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">Z</forename><surname>Jhanjhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Humayun</surname></persName>
		</author>
		<idno type="DOI">10.3390/healthcare11091222</idno>
		<ptr target="https://doi.org/10.3390/healthcare11091222" />
	</analytic>
	<monogr>
		<title level="j">Healthcare (Switzerland)</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="37,317.07,259.71,227.18,7.44;37,325.58,269.67,218.69,7.44;37,325.58,279.63,218.67,7.44;37,325.58,289.47,218.33,7.56;37,325.58,299.55,82.42,7.44" xml:id="b82">
	<analytic>
		<title level="a" type="main">An integrated design for classification and localization of diabetic foot ulcer based on cnn and yolov2-dfu models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sharif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Anjum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">U</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S A</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kadry</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2020.3045732</idno>
		<ptr target="https://doi.org/10.1109/ACCESS.2020.3045732" />
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="228586" to="228597" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="37,317.08,309.52,227.18,7.44;37,325.58,319.48,218.69,7.44;37,325.58,329.44,218.66,7.44;37,325.58,339.41,218.67,7.44;37,325.58,349.37,218.69,7.44;37,325.58,359.33,218.64,7.44;37,325.58,369.29,218.32,7.44;37,325.58,379.26,44.19,7.44" xml:id="b83">
	<analytic>
		<title level="a" type="main">An image based object recognition system for wound detection and classification of diabetic foot and venous leg ulcers</title>
		<author>
			<persName><forename type="first">J</forename><surname>Hüsers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Moelleken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Richter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Przysucha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Malihi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Busch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Götz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Heggemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hafer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wiemeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Babitsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Heidemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dissemond</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Erfurt-Berge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Hübner</surname></persName>
		</author>
		<idno type="DOI">10.3233/SHTI220397</idno>
		<ptr target="https://doi.org/10.3233/SHTI220397" />
	</analytic>
	<monogr>
		<title level="j">Studies in Health Technology and Informatics</title>
		<imprint>
			<biblScope unit="volume">294</biblScope>
			<biblScope unit="page" from="63" to="67" />
			<date type="published" when="2022">2022</date>
			<publisher>IOS Press BV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="37,317.08,389.22,227.19,7.44;37,325.58,399.18,218.68,7.44;37,325.58,409.03,218.66,7.56;37,325.58,419.11,130.17,7.44" xml:id="b84">
	<analytic>
		<title level="a" type="main">A unified framework for automatic detection of wound infection with artificial intelligence</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.3390/APP10155353</idno>
		<ptr target="https://doi.org/10.3390/APP10155353" />
	</analytic>
	<monogr>
		<title level="j">Applied Sciences (Switzerland)</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="37,317.08,429.07,227.19,7.44;37,325.58,439.03,218.64,7.44;37,325.58,449.00,218.67,7.44;37,325.58,458.96,218.63,7.44;37,325.58,468.92,29.61,7.44" xml:id="b85">
	<analytic>
		<title level="a" type="main">Analysis of chronic wound images using factorization based segmentation and machine learning methods</title>
		<author>
			<persName><forename type="first">I</forename><surname>Kavitha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Suganthi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ramakrishnan</surname></persName>
		</author>
		<idno type="DOI">10.1145/3155077.3155092</idno>
		<ptr target="https://doi.org/10.1145/3155077.3155092" />
	</analytic>
	<monogr>
		<title level="m">ACM International Conference Proceeding Series</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="74" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="37,317.08,478.88,227.17,7.44;37,325.58,488.85,218.67,7.44;37,325.58,498.81,218.72,7.44;37,325.58,508.65,196.84,7.56" xml:id="b86">
	<analytic>
		<title level="a" type="main">Computerassisted differential diagnosis of pyoderma gangrenosum and venous ulcers with deep neural networks</title>
		<author>
			<persName><forename type="first">M</forename><surname>Birkner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Schalk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Driesch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Schultz</surname></persName>
		</author>
		<idno type="DOI">10.3390/jcm11237103</idno>
		<ptr target="https://doi.org/10.3390/jcm11237103" />
	</analytic>
	<monogr>
		<title level="j">Journal of Clinical Medicine</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="37,317.07,518.74,227.20,7.44;37,325.58,528.69,218.69,7.44;37,325.58,538.65,218.68,7.44;37,325.58,548.50,218.66,7.56;37,325.58,558.58,179.83,7.44" xml:id="b87">
	<analytic>
		<title level="a" type="main">The random forest model has the best accuracy among the four pressure ulcer prediction models using machine learning algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Pi</surname></persName>
		</author>
		<idno type="DOI">10.2147/RMHP.S297838</idno>
		<ptr target="https://doi.org/10.2147/RMHP.S297838" />
	</analytic>
	<monogr>
		<title level="j">Risk Management and Healthcare Policy</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1175" to="1187" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="37,317.07,568.54,227.17,7.44;37,325.58,578.50,218.66,7.44;37,325.58,588.35,218.32,7.56;37,325.58,598.43,71.95,7.44" xml:id="b88">
	<analytic>
		<title level="a" type="main">Machine learning-based pressure ulcer prediction in modular critical care data</title>
		<author>
			<persName><forename type="first">P</forename><surname>Šín</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hokynková</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Marie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Andrea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Krč</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Podroužek</surname></persName>
		</author>
		<idno type="DOI">10.3390/diagnostics12040850</idno>
		<ptr target="https://doi.org/10.3390/diagnostics12040850" />
	</analytic>
	<monogr>
		<title level="j">Diagnostics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="37,317.07,608.39,227.11,7.44;37,325.58,618.36,218.69,7.44;37,325.58,628.20,218.36,7.56;37,325.58,638.28,67.09,7.44" xml:id="b89">
	<analytic>
		<title level="a" type="main">Real-time classification on oral ulcer images with residual network and image enhancement</title>
		<author>
			<persName><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Ma</surname></persName>
		</author>
		<idno type="DOI">10.1049/ipr2.12144</idno>
		<ptr target="https://doi.org/10.1049/ipr2.12144" />
	</analytic>
	<monogr>
		<title level="j">IET Image Processing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="641" to="646" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="37,317.07,648.24,227.19,7.44;37,325.58,658.21,218.69,7.44;37,325.58,668.17,218.66,7.44;37,325.58,678.01,187.63,7.56" xml:id="b90">
	<analytic>
		<title level="a" type="main">Exploiting machine learning algorithms to diagnose foot ulcers in diabetic patients</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Mahesh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Preethi</surname></persName>
		</author>
		<idno type="DOI">10.4108/eai.24-8-2021.170752</idno>
		<ptr target="https://doi.org/10.4108/eai.24-8-2021.170752" />
	</analytic>
	<monogr>
		<title level="j">EAI Endorsed Transactions on Pervasive Health and Technology</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="37,317.07,688.10,227.18,7.44;37,325.58,698.06,218.68,7.44;37,325.58,708.02,218.68,7.44;38,70.47,60.34,218.30,7.56;38,70.47,70.42,103.00,7.44" xml:id="b91">
	<analytic>
		<title level="a" type="main">Image analysis system for early detection of cardiothoracic surgery wound alterations based on artificial intel-ligence models</title>
		<author>
			<persName><forename type="first">C</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Guede-Fernández</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vigário</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Coelho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Fragata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Londral</surname></persName>
		</author>
		<idno type="DOI">10.3390/app13042120</idno>
		<ptr target="https://doi.org/10.3390/app13042120" />
	</analytic>
	<monogr>
		<title level="j">Applied Sciences (Switzerland)</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="38,61.95,80.38,227.20,7.44;38,70.47,90.34,218.67,7.44;38,70.47,100.31,218.65,7.44;38,70.47,110.15,218.30,7.56;38,70.47,120.23,91.03,7.44" xml:id="b92">
	<analytic>
		<title level="a" type="main">Predicting complex acute wound healing in patients from a wound expertise centre registry: A prognostic study</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Ubbink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lindeboom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Eskes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Brull</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Legemate</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Vermeulen</surname></persName>
		</author>
		<idno type="DOI">10.1111/iwj.12149</idno>
		<ptr target="https://doi.org/10.1111/iwj.12149" />
	</analytic>
	<monogr>
		<title level="j">International Wound Journal</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="531" to="536" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="38,61.95,130.19,227.20,7.44;38,70.47,140.16,218.62,7.44;38,70.47,150.00,218.66,7.56;38,70.47,160.08,151.34,7.44" xml:id="b93">
	<analytic>
		<title level="a" type="main">A granulation tissue detection model to track chronic wound healing in dm foot ulcers</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S Y</forename><surname>Lien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Tai</surname></persName>
		</author>
		<idno type="DOI">10.3390/electronics11162617</idno>
		<ptr target="https://doi.org/10.3390/electronics11162617" />
	</analytic>
	<monogr>
		<title level="j">Electronics (Switzerland)</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="38,61.95,170.05,227.18,7.44;38,70.47,180.01,218.68,7.44;38,70.47,189.97,218.68,7.44;38,70.47,199.82,218.66,7.56;38,70.47,209.90,184.01,7.44" xml:id="b94">
	<analytic>
		<title level="a" type="main">Comprehensive assessment of fine-grained wound images using a patch-based cnn with context-preserving attention</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Agu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lindsay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tulu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Strong</surname></persName>
		</author>
		<idno type="DOI">10.1109/OJEMB.2021.3092207</idno>
		<ptr target="https://doi.org/10.1109/OJEMB.2021.3092207" />
	</analytic>
	<monogr>
		<title level="j">IEEE Open Journal of Engineering in Medicine and Biology</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="224" to="234" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="38,61.95,219.86,227.18,7.44;38,70.47,229.82,218.67,7.44;38,70.47,239.79,218.69,7.44;38,70.47,249.63,218.66,7.56;38,70.47,259.71,159.32,7.44" xml:id="b95">
	<analytic>
		<title level="a" type="main">Chronic wound image augmentation and assessment using semisupervised progressive multi-granularity efficientnet</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Agu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lindsay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tulu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Strong</surname></persName>
		</author>
		<idno type="DOI">10.1109/OJEMB.2023.3248307</idno>
		<ptr target="https://doi.org/10.1109/OJEMB.2023.3248307" />
	</analytic>
	<monogr>
		<title level="j">IEEE Open Journal of Engineering in Medicine and Biology PP</title>
		<imprint>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="38,61.95,269.67,227.19,7.44;38,70.47,279.63,218.70,7.44;38,70.47,289.47,218.65,7.56;38,70.47,299.55,179.32,7.44" xml:id="b96">
	<analytic>
		<title level="a" type="main">Surgical wounds assessment system for self-care</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Kuo</surname></persName>
		</author>
		<idno type="DOI">10.1109/TSMC.2018.2856405</idno>
		<ptr target="https://doi.org/10.1109/TSMC.2018.2856405" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Systems, Man, and Cybernetics: Systems</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="5076" to="5091" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="38,61.95,309.52,227.20,7.44;38,70.47,319.48,218.69,7.44;38,70.47,329.44,218.67,7.44;38,70.47,339.29,218.66,7.56;38,70.47,349.37,176.04,7.44" xml:id="b97">
	<analytic>
		<title level="a" type="main">Utilization of smartphone and tablet camera photographs to predict healing of diabetes-related foot ulcers</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">B</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gryak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M R</forename><surname>Soroushmehr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Najarian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Wrobel</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.compbiomed.2020.104042</idno>
		<ptr target="https://doi.org/10.1016/j.compbiomed.2020.104042" />
	</analytic>
	<monogr>
		<title level="j">Computers in Biology and Medicine</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="38,61.95,359.33,227.20,7.44;38,70.47,369.29,218.68,7.44;38,70.47,379.26,218.69,7.44;38,70.47,389.10,218.66,7.56;38,70.47,399.18,217.27,7.44;38,54.90,409.14,234.24,7.44;38,70.47,419.11,218.66,7.44;38,70.47,429.07,218.63,7.44;38,70.47,438.91,218.65,7.56;38,70.47,449.00,30.09,7.44" xml:id="b98">
	<analytic>
		<title level="a" type="main">Machine learning models for predicting the risk of hard-to-heal diabetic foot ulcers in a chinese population</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Sanger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Ramshorst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mercan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hartzler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">A</forename><surname>Armstrong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Lordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Lober</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">L</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Tan</surname></persName>
		</author>
		<idno type="DOI">10.2147/DMSO.S383960</idno>
		<ptr target="https://doi.org/10.2147/DMSO.S383960" />
	</analytic>
	<monogr>
		<title level="j">Diabetes, Metabolic Syndrome and Obesity</title>
		<imprint>
			<biblScope unit="volume">176</biblScope>
			<biblScope unit="page" from="3347" to="3359" />
			<date type="published" when="2017">2017. 2022</date>
		</imprint>
	</monogr>
	<note>Physiology and behavior</note>
</biblStruct>

<biblStruct coords="38,61.95,458.96,227.18,7.44;38,70.47,468.92,218.68,7.44;38,70.47,478.88,218.69,7.44;38,70.47,488.73,218.67,7.56;38,70.47,498.81,87.09,7.44" xml:id="b99">
	<analytic>
		<title level="a" type="main">Machine learning models for synthesizing actionable care decisions on lower extremity wounds</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L H</forename><surname>Nguyena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Agua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tulua</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Diane Stronga</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Pedersena</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lindsayb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dunnb</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.smhl.2020.100139</idno>
		<ptr target="https://doi.org/10.1016/j.smhl.2020.100139" />
	</analytic>
	<monogr>
		<title level="j">Author manuscript</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1" to="30" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="38,61.78,508.77,227.35,7.44;38,70.47,518.74,218.66,7.44;38,70.47,528.57,218.36,7.56;38,70.47,538.65,117.96,7.44" xml:id="b100">
	<analytic>
		<title level="a" type="main">Predicting chronic wound healing time using machine learning</title>
		<author>
			<persName><forename type="first">M</forename><surname>Berezo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Budman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Deutscher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">T</forename><surname>Hess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hayes</surname></persName>
		</author>
		<idno type="DOI">10.1089/wound.2021.0073</idno>
		<ptr target="https://doi.org/10.1089/wound.2021.0073" />
	</analytic>
	<monogr>
		<title level="j">Advances in Wound Care</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="281" to="296" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="38,61.78,548.62,227.37,7.44;38,70.47,558.58,218.71,7.44;38,70.47,568.54,218.67,7.44;38,70.47,578.39,218.22,7.56;38,70.47,588.47,106.87,7.44" xml:id="b101">
	<analytic>
		<title level="a" type="main">Predictive risk models for wound infection-related hospitalization or ed visits in home health care using machine-learning algorithms</title>
		<author>
			<persName><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Woo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ojo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Topaz</surname></persName>
		</author>
		<idno type="DOI">10.1097/01.ASW.0000755928.30524.22</idno>
		<idno>ASW.0000755928.30524.22</idno>
		<ptr target="https://doi.org/10.1097/01" />
	</analytic>
	<monogr>
		<title level="j">Advances in Skin and Wound Care</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="38,61.78,598.43,227.38,7.44;38,70.47,608.39,218.69,7.44;38,70.47,618.24,218.70,7.56;38,70.46,628.32,100.88,7.44" xml:id="b102">
	<analytic>
		<title level="a" type="main">Rapid identification of slow healing wounds</title>
		<author>
			<persName><forename type="first">K</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Covington</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">K</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Januszyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Kirsner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Gurtner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">H</forename><surname>Shah</surname></persName>
		</author>
		<idno type="DOI">10.1111/wrr.12384.Rapid</idno>
		<ptr target="https://doi.org/10.1111/wrr.12384.Rapid" />
	</analytic>
	<monogr>
		<title level="j">Wound Repair Regen</title>
		<imprint>
			<biblScope unit="volume">176</biblScope>
			<biblScope unit="page" from="139" to="148" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="38,61.78,638.28,227.37,7.44;38,70.46,648.24,218.67,7.44;38,70.46,658.21,218.62,7.44;38,70.46,668.05,218.66,7.56;38,70.46,678.13,150.30,7.44" xml:id="b103">
	<analytic>
		<title level="a" type="main">A superpixel-driven deep learning approach for the analysis of dermatological wounds</title>
		<author>
			<persName><forename type="first">G</forename><surname>Blanco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J M</forename><surname>Traina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Traina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Azevedo-Marques</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E S</forename><surname>Jorge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">V N</forename><surname>Bedo</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cmpb.2019.105079</idno>
		<ptr target="https://doi.org/10.1016/j.cmpb.2019.105079" />
	</analytic>
	<monogr>
		<title level="j">Computer Methods and Programs in Biomedicine</title>
		<imprint>
			<biblScope unit="volume">183</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="38,316.89,60.45,227.35,7.44;38,325.58,70.41,218.66,7.44;38,325.58,80.25,218.67,7.56;38,325.58,90.34,161.69,7.44" xml:id="b104">
	<analytic>
		<title level="a" type="main">Integrating 3d model representation for an accurate non-invasive assessment of pressure injuries with deep learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Zahia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Garcia-Zapirain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Elmaghraby</surname></persName>
		</author>
		<idno type="DOI">10.3390/s20102933</idno>
		<ptr target="https://doi.org/10.3390/s20102933" />
	</analytic>
	<monogr>
		<title level="j">Sensors (Switzerland)</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="38,316.89,100.30,227.34,7.44;38,325.58,110.26,218.63,7.44;38,325.58,120.22,218.64,7.44;38,325.58,130.07,218.60,7.56;38,325.58,140.15,29.61,7.44" xml:id="b105">
	<analytic>
		<title level="a" type="main">Deep learning approach based on superpixel segmentation assisted labeling for automatic pressure ulcer diagnosis</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Christian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0264139</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0264139" />
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="38,316.89,150.11,227.36,7.44;38,325.58,160.08,218.67,7.44;38,325.58,170.04,218.68,7.44;38,325.58,179.88,218.66,7.56;38,325.58,189.96,150.30,7.44" xml:id="b106">
	<analytic>
		<title level="a" type="main">Segmenting skin ulcers and measuring the wound area using deep convolutional networks</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">Y T</forename><surname>Chino</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Scabora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Cazzolato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E S</forename><surname>Jorge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Traina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J M</forename><surname>Traina</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cmpb.2020.105376</idno>
		<ptr target="https://doi.org/10.1016/j.cmpb.2020.105376" />
	</analytic>
	<monogr>
		<title level="j">Computer Methods and Programs in Biomedicine</title>
		<imprint>
			<biblScope unit="volume">191</biblScope>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="38,316.89,199.93,227.36,7.44;38,325.58,209.78,218.68,7.55;38,325.58,219.86,197.22,7.44" xml:id="b107">
	<analytic>
		<title level="a" type="main">Computational approach for chronic wound tissue characterization</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chakraborty</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.imu.2019.100162</idno>
		<ptr target="https://doi.org/10.1016/j.imu.2019.100162" />
	</analytic>
	<monogr>
		<title level="j">Informatics in Medicine Unlocked</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page">100162</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="38,316.89,229.82,227.36,7.44;38,325.58,239.79,218.65,7.44;38,325.58,249.75,218.69,7.44;38,325.58,259.59,218.12,7.56;38,325.58,269.68,28.70,7.44" xml:id="b108">
	<analytic>
		<title level="a" type="main">An application for wound diagnosis and treatment</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G R</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">A A</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Guelfi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jesus</forename><surname>Perez Alcazar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Azevedo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Kofuji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename></persName>
		</author>
		<idno type="DOI">10.1007/s42600-022-00213-3</idno>
		<ptr target="https://doi.org/10.1007/s42600-022-00213-3" />
	</analytic>
	<monogr>
		<title level="j">Research on Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="629" to="645" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="38,316.89,279.63,227.37,7.44;38,325.58,289.59,218.70,7.44;38,325.58,299.56,218.67,7.44;38,325.58,309.40,209.71,7.56" xml:id="b109">
	<analytic>
		<title level="a" type="main">Automatic segmentation and measurement of pressure injuries using deep learning models and a lidar camera</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Christian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Tai</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-022-26812-9</idno>
		<ptr target="https://doi.org/10.1038/s41598-022-26812-9" />
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="38,316.89,319.48,227.34,7.44;38,325.58,329.44,218.65,7.44;38,325.58,339.29,218.66,7.56;38,325.58,349.37,165.42,7.44" xml:id="b110">
	<analytic>
		<title level="a" type="main">Varicose ulcer(c6) wound image tissue classification using multidimensional convolutional neural networks</title>
		<author>
			<persName><forename type="first">V</forename><surname>Rajathi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">R</forename><surname>Bhavani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Jiji</surname></persName>
		</author>
		<idno type="DOI">10.1080/13682199.2019.1663083</idno>
		<ptr target="https://doi.org/10.1080/13682199.2019.1663083" />
	</analytic>
	<monogr>
		<title level="j">Imaging Science Journal</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="374" to="384" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="38,316.89,359.33,227.36,7.44;38,325.58,369.30,218.64,7.44;38,325.58,379.26,218.68,7.44;38,325.58,389.22,218.66,7.44;38,325.58,399.07,218.15,7.56;38,325.58,409.15,44.70,7.44" xml:id="b111">
	<analytic>
		<title level="a" type="main">Software-based method for automated segmentation and measurement of wounds on photographs using mask r-cnn: a validation study</title>
		<author>
			<persName><forename type="first">M</forename><surname>Privalov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Beisemann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Barbari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Mandelka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Syrek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Grützner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Vetter</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10278-021-00490-x</idno>
		<ptr target="https://doi.org/10.1007/s10278-021-00490-x" />
	</analytic>
	<monogr>
		<title level="j">Journal of Digital Imaging</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="788" to="797" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="38,316.89,419.11,227.35,7.44;38,325.58,429.07,218.66,7.44;38,325.58,439.04,218.68,7.44;38,325.58,448.88,218.66,7.56;38,325.58,458.96,149.45,7.44" xml:id="b112">
	<analytic>
		<title level="a" type="main">Ai-assisted assessment of wound tissue with automatic color and measurement calibration on images taken with a smartphone</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chairat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chaichulee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Dissaneewate</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wangkulangkul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Kongpanichakul</surname></persName>
		</author>
		<idno type="DOI">10.3390/healthcare11020273</idno>
		<ptr target="https://doi.org/10.3390/healthcare11020273" />
	</analytic>
	<monogr>
		<title level="j">Healthcare (Switzerland)</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="38,316.89,468.92,227.36,7.44;38,325.58,478.89,218.69,7.44;38,325.58,488.85,218.64,7.44;38,325.58,498.69,218.37,7.56;38,325.58,508.77,139.36,7.44" xml:id="b113">
	<analytic>
		<title level="a" type="main">Fine-grained diabetic wound depth and granulation tissue amount assessment using bilinear convolutional neural network</title>
		<author>
			<persName><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Agu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Wagh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Lindsay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tulu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Strong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kan</surname></persName>
		</author>
		<idno type="DOI">10.1109/ACCESS.2019.2959027</idno>
		<ptr target="https://doi.org/10.1109/ACCESS.2019.2959027" />
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="179151" to="179162" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="38,316.89,518.74,227.35,7.44;38,325.58,528.69,218.68,7.44;38,325.58,538.65,218.68,7.44;38,325.58,548.50,218.33,7.56;38,325.58,558.58,68.22,7.44" xml:id="b114">
	<analytic>
		<title level="a" type="main">Chronic wound assessment and infection detection method</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">C</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Lai</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12911-019-0813-0</idno>
		<idno>12911-019-0813-0</idno>
		<ptr target="https://doi.org/10.1186/s" />
	</analytic>
	<monogr>
		<title level="j">BMC Medical Informatics and Decision Making</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="38,316.89,568.54,227.38,7.44;38,325.58,578.51,218.68,7.44;38,325.58,588.35,218.66,7.56;38,325.58,598.43,162.80,7.44" xml:id="b115">
	<analytic>
		<title level="a" type="main">Skin tear classification using machine learning from digital rgb image</title>
		<author>
			<persName><forename type="first">T</forename><surname>Nagata</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Noyori</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Noguchi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Nakagami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kitamura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Sanada</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jtv.2021.01.004</idno>
		<ptr target="https://doi.org/10.1016/j.jtv.2021.01.004" />
	</analytic>
	<monogr>
		<title level="j">Journal of Tissue Viability</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="588" to="593" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="38,316.89,608.39,227.35,7.44;38,325.58,618.36,218.70,7.44;38,325.58,628.32,218.62,7.44;38,325.58,638.16,218.66,7.56;38,325.58,648.25,145.01,7.44" xml:id="b116">
	<analytic>
		<title level="a" type="main">Clinical validation of computer vision and artificial intelligence algorithms for wound measurement and tissue classification in wound care</title>
		<author>
			<persName><forename type="first">D</forename><surname>Reifs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Casanova-Lozano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Reig-Bolaño</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Grau-Carrion</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.imu.2023.101185</idno>
		<ptr target="https://doi.org/10.1016/j.imu.2023.101185" />
	</analytic>
	<monogr>
		<title level="j">Informatics in Medicine Unlocked</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
